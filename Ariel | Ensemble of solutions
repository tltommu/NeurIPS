{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70367,"databundleVersionId":9188054,"sourceType":"competition"},{"sourceId":191155259,"sourceType":"kernelVersion"},{"sourceId":196522559,"sourceType":"kernelVersion"}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"One of the [outstanding members](https://www.kaggle.com/cdeotte) of the Kaggle community, grandmaster, gives a link to his [work](https://www.kaggle.com/code/cdeotte/top-solutions-ensemble-0-947), where he shows the refinement of the prediction using an experimental example. In order to try to refine our predictions at the [NeurIPS - Ariel Data Challenge 2024](https://www.kaggle.com/competitions/ariel-data-challenge-2024/leaderboard) competition\n\n**[Ariel | Ensemble of solutions](https://www.kaggle.com/code/vyacheslavbolotin/ensemble-of-solutions/edit)**: Leaderboard=0.5??\n\n1. (0.514) [ariel_only_correlation](https://www.kaggle.com/code/sergeifironov/ariel-only-correlation) by grandmaster [Sergei Fironov](https://www.kaggle.com/sergeifironov)\n2. (0.515) [ariel_only_correlation LB: 0.515](https://www.kaggle.com/code/jaejohn/ariel-only-correlation-lb-0-515) by contributor [G John Rao](https://www.kaggle.com/jaejohn)\n3. (0.446) [Fork of NeurIPS Ariel 2024 - Starter 5be123](https://www.kaggle.com/code/regisvargas/fork-of-neurips-ariel-2024-starter-5be123) by expert [Regis Vargas](https://www.kaggle.com/regisvargas)\n4. (0.441) [AD24[TRAIN-INF]Ridge_AddFE[LB.441]](https://www.kaggle.com/code/hideyukizushi/ad24-train-inf-ridge-addfe-lb-441) by expert [yukiZ](https://www.kaggle.com/hideyukizushi)\n5. (0.434) [NeurIPS Ariel 2024 - Starter withdifferentparametr](https://www.kaggle.com/code/bingyuniu/neurips-ariel-2024-starter-withdifferentparametr) by contributor [yu🐂](https://www.kaggle.com/bingyuniu)\n6. ()\n7. (0.517) [ariel_only_correlation | param upd[LB.517]](https://www.kaggle.com/code/hideyukizushi/ariel-only-correlation-param-upd-lb-517) by expert [yukiZ](https://www.kaggle.com/hideyukizushi)\n8. (0.544) [Ariel Data Challenge 2024](https://www.kaggle.com/code/xiaocao123/ariel-data-challenge-2024) by expert [qianc](https://www.kaggle.com/xiaocao123)\n9. (0.545) [LB=0.545](https://www.kaggle.com/code/xiaocao123/lb-0-545) by expert [qianc](https://www.kaggle.com/xiaocao123)\n\n\n#### options\n\n- option 1 -> LB=0.515 work (1,2)\n- option 2 -> LB= ?.??? work (3,4,5) \n- option 3 -> LB=0.000 work (1,2,3)         \n- option 4 -> LB= ?.??? work (4,5)\n- option 5 -> LB=0.514 work (1,2) + weight (0.15+0.85)\n- option 7 -> LB=0.515 work (1,2) + weight (0.85+0.15)\n- option 8 -> LB=0.515 work (1,2) + weight (0.07+0.93)\n- option 9 -> LB=0.517 work (2,7)\n- option 10 -> LB=0.516 work (1,2,7)\n- option 11 -> LB=0.517 work (2,7) + weight (0.10+0.90)\n- option 12 -> LB=0.517 work (2,7) + weight (0.05+0.95)\n- option 14 -> LB=0.544 work (7,8) + weight (0.005+0.995)\n- option 15 -> LB=0.544 work (7,8) + weight (0.008+0.992)\n- option 16 -> LB=0.544 work (7,8) + weight (0.011+0.989)\n- option 17 -> LB=0.544 work (7,8) + weight (0.015+0.985)\n- option 18 -> LB=0.544 work (7,8) + weight (0.02+0.98)\n- option 19 -> LB=0.544 work (7,8) + weight (0.05+0.95)\n- option 20 -> LB=0.544 work (7,8) + weight (0.07+0.93)\n- option 21 -> LB=0.544 work (7,8) + weight (0.03+0.97)\n- option 22 -> LB=0.544 work (7,8) + weight (0.035+0.965)\n- option 23 -> LB=0.544 work (7,8) + weight (0.026+0.974)\n- option 24 -> LB=0.544 work (7,8) + weight (0.032+0.968)\n- option 25 -> LB=0.544 work (7,8) + weight (0.031+0.969)\n- option 26 -> LB=0.544 work (7,8) + weight (0.028+0.972)\n- **option 27** -> LB=**0.544** work (7,8) + weight (0.0305+0.9695) **previus.1 best option**\n- option 28 -> LB=0.544 work (7,8) + weight (0.0290+0.9710)\n- option 29 -> LB=0.544 work (7,8) + weight (0.0302+0.9698)\n- option 33 -> LB=0.545 work (7, 9.1, 9.2, 9.3)\n- option 34 -> LB=0.545 work (7,9) + weight (0.0298+0.9702) \n- option 35 -> LB=**0.545** work (7,9) + weight (0.0302+0.9698) **best option**\n\nsome rezults\n* option.21 < option.28 < **option.27** (0.544 version.52)\n* option.33 < option.34 < **option.35** (0.545 version.59) has an unclear operation: sigma = np.ones_like(all_s) * 0.0001422\n\nbest option:\n- option 27 -> LB=**0.544** work (7,8) + weight (0.0305+0.9695), **option.27**, **version 52** \n- option 35 -> LB=**0.545** work (7,9) + weight (0.0302+0.9698), **option.35**, **version 59**\n\ncurrent option:\n- ?\n\nnext option: \n- option 30 -> LB=0.54? work (7,8) + weight (0.0295+0.9705)\n- option 31 -> LB=0.54? work (1,8) + weights\n- option 32 -> LB=0.54? work (2,8) + weights\n\n\nThe copyright holder of the eighth notebook from the list specifies his work with the line sigma = np.ones_like(all_s) * 0.0001422 and shows the rise to the leaderboard. Let this be the ninth work on our list!\n","metadata":{}},{"cell_type":"code","source":"LAUNCH_VARIANT = 'option 35'","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:39:43.554284Z","iopub.execute_input":"2024-09-18T11:39:43.554761Z","iopub.status.idle":"2024-09-18T11:39:43.588738Z","shell.execute_reply.started":"2024-09-18T11:39:43.554719Z","shell.execute_reply":"2024-09-18T11:39:43.587572Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## [ariel_only_correlation](https://www.kaggle.com/code/vyacheslavbolotin/isic-2024-2-image-lines)\n\n### [Sergei Fironov](https://www.kaggle.com/sergeifironov)","metadata":{}},{"cell_type":"markdown","source":"### preface \nI was inspired by @AmbrosM idea https://www.kaggle.com/competitions/ariel-data-challenge-2024/discussion/530152#2969648\n\nThe idea of ​​this approach is to predict the average answer for each test sample. Instead of building models, we will search for the correct answer experimentally. We will select for each spectrum such a multiplier that the transit part multiplied by it will \"line up\" with the other points. The line can be either a straight line or a polynomial up to the 5th degree. For selection, we will use the Nelder-Mead method. The found multiplication factor minus one is our answer.\n\nThere are some changes in data preparation here.\n* dt for dark calibration changed in favor https://www.kaggle.com/code/gordonyip/update-calibrating-and-binning-astronomical-data/comments#2964759\n* signal clipped to zero due this https://www.kaggle.com/competitions/ariel-data-challenge-2024/discussion/530247#2970709\n* I masked hot and dead pixels with NaN in flat and averaging through spatial dimension.","metadata":{}},{"cell_type":"markdown","source":"### **upd for version 2**: it seems I forgot to remove **5x sigma** copied from somewhere. I wonder how this will affect the score.","metadata":{}},{"cell_type":"markdown","source":"### preprocess the data","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import matplotlib.pyplot as plt\n# import numpy as np\n# import seaborn as sns\n# import scipy.stats\n# from tqdm import tqdm\n\n# from sklearn.model_selection import cross_val_predict\n# from sklearn.linear_model import Ridge\n# from sklearn.metrics import r2_score, mean_squared_error\n# import itertools\n# from scipy.optimize import minimize\n# from functools import partial\n# import random, os\n# from astropy.stats import sigma_clip","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.597882Z","iopub.execute_input":"2024-09-18T11:39:43.598531Z","iopub.status.idle":"2024-09-18T11:39:43.605233Z","shell.execute_reply.started":"2024-09-18T11:39:43.598478Z","shell.execute_reply":"2024-09-18T11:39:43.603494Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# test_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/test_adc_info.csv',\n#                            index_col='planet_id')\n# axis_info = pd.read_parquet('/kaggle/input/ariel-data-challenge-2024/axis_info.parquet')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.607418Z","iopub.execute_input":"2024-09-18T11:39:43.607891Z","iopub.status.idle":"2024-09-18T11:39:43.618842Z","shell.execute_reply.started":"2024-09-18T11:39:43.607839Z","shell.execute_reply":"2024-09-18T11:39:43.617330Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# def apply_linear_corr(linear_corr,clean_signal):\n#     linear_corr = np.flip(linear_corr, axis=0)\n#     for x, y in itertools.product(\n#                 range(clean_signal.shape[1]), range(clean_signal.shape[2])\n#             ):\n#         poli = np.poly1d(linear_corr[:, x, y])\n#         clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n#     return clean_signal\n\n# def clean_dark(signal, dark, dt):\n#     dark = np.tile(dark, (signal.shape[0], 1, 1))\n#     signal -= dark* dt[:, np.newaxis, np.newaxis]\n#     return signal\n\n# def preproc(dataset, adc_info, sensor, binning = 15):\n#     cut_inf, cut_sup = 39, 321\n#     sensor_sizes_dict = {\"AIRS-CH0\":[[11250, 32, 356], [1, 32, cut_sup-cut_inf]], \"FGS1\":[[135000, 32, 32], [1, 32, 32]]}\n#     binned_dict = {\"AIRS-CH0\":[11250 // binning // 2, 282], \"FGS1\":[135000 // binning // 2]}\n#     linear_corr_dict = {\"AIRS-CH0\":(6, 32, 356), \"FGS1\":(6, 32, 32)}\n#     planet_ids = adc_info.index\n    \n#     feats = []\n#     for i, planet_id in tqdm(list(enumerate(planet_ids))):\n#         signal = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/{planet_id}/{sensor}_signal.parquet').to_numpy()\n#         dark_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dark.parquet', engine='pyarrow').to_numpy()\n#         dead_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dead.parquet', engine='pyarrow').to_numpy()\n#         flat_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/flat.parquet', engine='pyarrow').to_numpy()\n#         linear_corr = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/linear_corr.parquet').values.astype(np.float64).reshape(linear_corr_dict[sensor])\n\n#         signal = signal.reshape(sensor_sizes_dict[sensor][0]) \n#         gain = adc_info[f'{sensor}_adc_gain'].values[i]\n#         offset = adc_info[f'{sensor}_adc_offset'].values[i]\n#         signal = signal / gain + offset\n        \n#         hot = sigma_clip(\n#             dark_frame, sigma=5, maxiters=5\n#         ).mask\n        \n#         if sensor != \"FGS1\":\n#             signal = signal[:, :, cut_inf:cut_sup] #11250 * 32 * 282\n#             #dt = axis_info['AIRS-CH0-integration_time'].dropna().values\n#             dt = np.ones(len(signal))*0.1 \n#             dt[1::2] += 4.5 #@bilzard idea\n#             linear_corr = linear_corr[:, :, cut_inf:cut_sup]\n#             dark_frame = dark_frame[:, cut_inf:cut_sup]\n#             dead_frame = dead_frame[:, cut_inf:cut_sup]\n#             flat_frame = flat_frame[:, cut_inf:cut_sup]\n#             hot = hot[:, cut_inf:cut_sup]\n#         else:\n#             dt = np.ones(len(signal))*0.1\n#             dt[1::2] += 0.1\n            \n#         signal = signal.clip(0) #@graySnow idea\n#         linear_corr_signal = apply_linear_corr(linear_corr, signal)\n#         signal = clean_dark(linear_corr_signal, dark_frame, dt)\n        \n#         flat = flat_frame.reshape(sensor_sizes_dict[sensor][1])\n#         flat[dead_frame.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n#         flat[hot.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n#         signal = signal / flat\n        \n#         if sensor == \"FGS1\":\n#             signal = signal.reshape((sensor_sizes_dict[sensor][0][0], sensor_sizes_dict[sensor][0][1]*sensor_sizes_dict[sensor][0][2]))\n        \n#         mean_signal = np.nanmean(signal, axis=1) # mean over the 32*32(FGS1) or 32(CH0) pixels\n#         cds_signal = (mean_signal[1::2] - mean_signal[0::2])\n        \n#         binned = np.zeros((binned_dict[sensor]))\n#         for j in range(cds_signal.shape[0] // binning):\n#             binned[j] = cds_signal[j*binning:j*binning+binning].mean(axis=0)\n                   \n#         if sensor == \"FGS1\":\n#             binned = binned.reshape((binned.shape[0],1))\n            \n#         feats.append(binned)\n        \n#     return np.stack(feats)\n    \n# pre_train = np.concatenate([preproc('test', test_adc_info, \"FGS1\", 30*12), preproc('test', test_adc_info, \"AIRS-CH0\", 30)], axis=2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.621656Z","iopub.execute_input":"2024-09-18T11:39:43.622177Z","iopub.status.idle":"2024-09-18T11:39:43.634296Z","shell.execute_reply.started":"2024-09-18T11:39:43.622134Z","shell.execute_reply":"2024-09-18T11:39:43.632996Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### fit polynoms for each sample","metadata":{}},{"cell_type":"code","source":"# def phase_detector(signal):\n#     phase1, phase2 = None, None\n#     best_drop = 0\n#     for i in range(50//2,150//2):        \n#         t1 = signal[i:i+20//2].max() - signal[i:i+20//2].min()\n#         if t1 > best_drop:\n#             phase1 = i+(20+5)//2\n#             best_drop = t1\n    \n#     best_drop = 0\n#     for i in range(200//2,250//2):\n#         t1 = signal[i:i+20//2].max() - signal[i:i+20//2].min()\n#         if t1 > best_drop:\n#             phase2 = i-5//2\n#             best_drop = t1\n    \n#     return phase1, phase2\n\n# def try_s(signal, p1, p2, deg, s):\n#     out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n#     x, y = out, signal[out].tolist()\n#     x = x + list(range(p1,p2))\n\n#     y = y + (signal[p1:p2] * (1 + s[0])).tolist()\n#     z = np.polyfit(x, y, deg)\n#     p = np.poly1d(z)\n#     q = np.abs(p(x) - y).mean()\n\n#     if s < 1e-4:\n#         return q + 1e3\n\n#     return q\n    \n# def calibrate_signal(signal):\n#     p1,p2 = phase_detector(signal)\n\n#     best_deg, best_score = 1, 1e12\n#     for deg in range(1, 6):\n#         f = partial(try_s, signal, p1, p2, deg)\n#         r = minimize(f, [0.001], method = 'Nelder-Mead')\n#         s = r.x[0]\n\n#         out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n#         x, y = out, signal[out].tolist()\n#         x = x + list(range(p1,p2))\n#         y = y + (signal[p1:p2] * (1 + s)).tolist()\n    \n#         z = np.polyfit(x, y, deg)\n#         p = np.poly1d(z)\n#         q = np.abs(p(x) - y).mean()\n        \n#         if q < best_score:\n#             best_score = q\n#             best_deg = deg\n        \n#         print(deg, q)\n            \n#     z = np.polyfit(x, y, best_deg)\n#     p = np.poly1d(z)\n\n#     return s, x, y, p(x)\n\n# def calibrate_train(signal):\n#     p1,p2 = phase_detector(signal)\n    \n#     best_deg, best_score = 1, 1e12\n#     for deg in range(1, 6):\n#         f = partial(try_s, signal, p1, p2, deg)\n#         r = minimize(f, [0.001], method = 'Nelder-Mead')\n#         s = r.x[0]\n\n#         out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n#         x, y = out, signal[out].tolist()\n#         x = x + list(range(p1,p2))\n#         y = y + (signal[p1:p2] * (1 + s)).tolist()\n    \n#         z = np.polyfit(x, y, deg)\n#         p = np.poly1d(z)\n#         q = np.abs(p(x) - y).mean()\n        \n#         if q < best_score:\n#             best_score = q\n#             best_deg = deg\n            \n#     z = np.polyfit(x, y, best_deg)\n#     p = np.poly1d(z)\n    \n#     return s, p(np.arange(signal.shape[0])), p1, p2\n\n\n# train = pre_train.copy()\n# all_s = []\n# for i in range(len(test_adc_info)):\n#     signal = train[i,:,1:].mean(axis=1)\n#     s, p, p1, p2 = calibrate_train(pre_train[i,:,1:].mean(axis=1))\n#     all_s.append(s)\n        \n# #copy answer 283 times because we predict mean value\n# train_s = np.repeat(np.array(all_s), 283).reshape((len(all_s), 283))        \n# train_sigma = np.ones_like(train_s) * 0.00016","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.684513Z","iopub.execute_input":"2024-09-18T11:39:43.685004Z","iopub.status.idle":"2024-09-18T11:39:43.694536Z","shell.execute_reply.started":"2024-09-18T11:39:43.684963Z","shell.execute_reply":"2024-09-18T11:39:43.693015Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Probably we can accurately estimate sigma from train","metadata":{}},{"cell_type":"code","source":"# n = 0\n# s, x, y, y_new = calibrate_signal(pre_train[n,:,1:].mean(axis=1))\n# plt.scatter(x,y)\n# plt.scatter(x,y_new)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.696858Z","iopub.execute_input":"2024-09-18T11:39:43.697374Z","iopub.status.idle":"2024-09-18T11:39:43.710013Z","shell.execute_reply.started":"2024-09-18T11:39:43.697319Z","shell.execute_reply":"2024-09-18T11:39:43.708545Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"I call the orange line \"starline\". This is probably what we would see if the planet weren't in the way.","metadata":{}},{"cell_type":"markdown","source":"### Making submission","metadata":{}},{"cell_type":"code","source":"# ss = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv')\n\n# preds = train_s.clip(0)\n# sigmas = train_sigma\n# submission = pd.DataFrame(np.concatenate([preds,sigmas], axis=1), columns=ss.columns[1:])\n# submission.index = test_adc_info.index\n# submission.to_csv('submission_1.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.712005Z","iopub.execute_input":"2024-09-18T11:39:43.712450Z","iopub.status.idle":"2024-09-18T11:39:43.723551Z","shell.execute_reply.started":"2024-09-18T11:39:43.712402Z","shell.execute_reply":"2024-09-18T11:39:43.722094Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# submission","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.725227Z","iopub.execute_input":"2024-09-18T11:39:43.725657Z","iopub.status.idle":"2024-09-18T11:39:43.740973Z","shell.execute_reply.started":"2024-09-18T11:39:43.725607Z","shell.execute_reply":"2024-09-18T11:39:43.739701Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## [ariel_local_purple_hat_inference](https://www.kaggle.com/code/sergeifironov/ariel-local-purple-hat-inference)\n\n### [Sergei Fironov](https://www.kaggle.com/sergeifironov)","metadata":{}},{"cell_type":"code","source":"","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [ariel_only_correlation LB: 0.515](https://www.kaggle.com/code/jaejohn/ariel-only-correlation-lb-0-515)\n\n### [G John Rao](https://www.kaggle.com/jaejohn)","metadata":{}},{"cell_type":"markdown","source":"### preface \nI was inspired by @AmbrosM idea https://www.kaggle.com/competitions/ariel-data-challenge-2024/discussion/530152#2969648\n\nThe idea of ​​this approach is to predict the average answer for each test sample. Instead of building models, we will search for the correct answer experimentally. We will select for each spectrum such a multiplier that the transit part multiplied by it will \"line up\" with the other points. The line can be either a straight line or a polynomial up to the 5th degree. For selection, we will use the Nelder-Mead method. The found multiplication factor minus one is our answer.\n\nThere are some changes in data preparation here.\n* dt for dark calibration changed in favor https://www.kaggle.com/code/gordonyip/update-calibrating-and-binning-astronomical-data/comments#2964759\n* signal clipped to zero due this https://www.kaggle.com/competitions/ariel-data-challenge-2024/discussion/530247#2970709\n* I masked hot and dead pixels with NaN in flat and averaging through spatial dimension.","metadata":{}},{"cell_type":"markdown","source":"### **upd for version 2**: it seems I forgot to remove **5x sigma** copied from somewhere. I wonder how this will affect the score.\n\n#### preprocess the data","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import matplotlib.pyplot as plt\n# import numpy as np\n# import seaborn as sns\n# import scipy.stats\n# from tqdm import tqdm\n\n# from sklearn.model_selection import cross_val_predict\n# from sklearn.linear_model import Ridge\n# from sklearn.metrics import r2_score, mean_squared_error\n# import itertools\n# from scipy.optimize import minimize\n# from functools import partial\n# import random, os\n# from astropy.stats import sigma_clip","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.744036Z","iopub.execute_input":"2024-09-18T11:39:43.744533Z","iopub.status.idle":"2024-09-18T11:39:43.754880Z","shell.execute_reply.started":"2024-09-18T11:39:43.744483Z","shell.execute_reply":"2024-09-18T11:39:43.753393Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# test_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/test_adc_info.csv',\n#                            index_col='planet_id')\n# axis_info = pd.read_parquet('/kaggle/input/ariel-data-challenge-2024/axis_info.parquet')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.757108Z","iopub.execute_input":"2024-09-18T11:39:43.757627Z","iopub.status.idle":"2024-09-18T11:39:43.767984Z","shell.execute_reply.started":"2024-09-18T11:39:43.757562Z","shell.execute_reply":"2024-09-18T11:39:43.766415Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# def apply_linear_corr(linear_corr,clean_signal):\n#     linear_corr = np.flip(linear_corr, axis=0)\n#     for x, y in itertools.product(\n#                 range(clean_signal.shape[1]), range(clean_signal.shape[2])\n#             ):\n#         poli = np.poly1d(linear_corr[:, x, y])\n#         clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n#     return clean_signal\n\n# def clean_dark(signal, dark, dt):\n#     dark = np.tile(dark, (signal.shape[0], 1, 1))\n#     signal -= dark* dt[:, np.newaxis, np.newaxis]\n#     return signal\n\n# def preproc(dataset, adc_info, sensor, binning = 15):\n#     cut_inf, cut_sup = 39, 321\n#     sensor_sizes_dict = {\"AIRS-CH0\":[[11250, 32, 356], [1, 32, cut_sup-cut_inf]], \"FGS1\":[[135000, 32, 32], [1, 32, 32]]}\n#     binned_dict = {\"AIRS-CH0\":[11250 // binning // 2, 282], \"FGS1\":[135000 // binning // 2]}\n#     linear_corr_dict = {\"AIRS-CH0\":(6, 32, 356), \"FGS1\":(6, 32, 32)}\n#     planet_ids = adc_info.index\n    \n#     feats = []\n#     for i, planet_id in tqdm(list(enumerate(planet_ids))):\n#         signal = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/{planet_id}/{sensor}_signal.parquet').to_numpy()\n#         dark_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dark.parquet', engine='pyarrow').to_numpy()\n#         dead_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dead.parquet', engine='pyarrow').to_numpy()\n#         flat_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/flat.parquet', engine='pyarrow').to_numpy()\n#         linear_corr = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/linear_corr.parquet').values.astype(np.float64).reshape(linear_corr_dict[sensor])\n\n#         signal = signal.reshape(sensor_sizes_dict[sensor][0]) \n#         gain = adc_info[f'{sensor}_adc_gain'].values[i]\n#         offset = adc_info[f'{sensor}_adc_offset'].values[i]\n#         signal = signal / gain + offset\n        \n#         hot = sigma_clip(\n#             dark_frame, sigma=5, maxiters=5\n#         ).mask\n        \n#         if sensor != \"FGS1\":\n#             signal = signal[:, :, cut_inf:cut_sup] #11250 * 32 * 282\n#             #dt = axis_info['AIRS-CH0-integration_time'].dropna().values\n#             dt = np.ones(len(signal))*0.1 \n#             dt[1::2] += 4.5 #@bilzard idea\n#             linear_corr = linear_corr[:, :, cut_inf:cut_sup]\n#             dark_frame = dark_frame[:, cut_inf:cut_sup]\n#             dead_frame = dead_frame[:, cut_inf:cut_sup]\n#             flat_frame = flat_frame[:, cut_inf:cut_sup]\n#             hot = hot[:, cut_inf:cut_sup]\n#         else:\n#             dt = np.ones(len(signal))*0.1\n#             dt[1::2] += 0.1\n            \n#         signal = signal.clip(0) #@graySnow idea\n#         linear_corr_signal = apply_linear_corr(linear_corr, signal)\n#         signal = clean_dark(linear_corr_signal, dark_frame, dt)\n        \n#         flat = flat_frame.reshape(sensor_sizes_dict[sensor][1])\n#         flat[dead_frame.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n#         flat[hot.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n#         signal = signal / flat\n        \n#         if sensor == \"FGS1\":\n#             signal = signal.reshape((sensor_sizes_dict[sensor][0][0], sensor_sizes_dict[sensor][0][1]*sensor_sizes_dict[sensor][0][2]))\n        \n#         mean_signal = np.nanmean(signal, axis=1) # mean over the 32*32(FGS1) or 32(CH0) pixels\n#         cds_signal = (mean_signal[1::2] - mean_signal[0::2])\n        \n#         binned = np.zeros((binned_dict[sensor]))\n#         for j in range(cds_signal.shape[0] // binning):\n#             binned[j] = cds_signal[j*binning:j*binning+binning].mean(axis=0)\n                   \n#         if sensor == \"FGS1\":\n#             binned = binned.reshape((binned.shape[0],1))\n            \n#         feats.append(binned)\n        \n#     return np.stack(feats)\n    \n# pre_train = np.concatenate([preproc('test', test_adc_info, \"FGS1\", 30*12), preproc('test', test_adc_info, \"AIRS-CH0\", 30)], axis=2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.771720Z","iopub.execute_input":"2024-09-18T11:39:43.772399Z","iopub.status.idle":"2024-09-18T11:39:43.783159Z","shell.execute_reply.started":"2024-09-18T11:39:43.772309Z","shell.execute_reply":"2024-09-18T11:39:43.781751Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### fit polynoms for each sample","metadata":{}},{"cell_type":"code","source":"# def phase_detector(signal):\n#     phase1, phase2 = None, None\n#     best_drop = 0\n#     for i in range(50//2,150//2):        \n#         t1 = signal[i:i+20//2].max() - signal[i:i+20//2].min()\n#         if t1 > best_drop:\n#             phase1 = i+(20+5)//2\n#             best_drop = t1\n    \n#     best_drop = 0\n#     for i in range(200//2,250//2):\n#         t1 = signal[i:i+20//2].max() - signal[i:i+20//2].min()\n#         if t1 > best_drop:\n#             phase2 = i-5//2\n#             best_drop = t1\n    \n#     return phase1, phase2\n\n# def try_s(signal, p1, p2, deg, s):\n#     out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n#     x, y = out, signal[out].tolist()\n#     x = x + list(range(p1,p2))\n\n#     y = y + (signal[p1:p2] * (1 + s[0])).tolist()\n#     z = np.polyfit(x, y, deg)\n#     p = np.poly1d(z)\n#     q = np.abs(p(x) - y).mean()\n\n#     if s < 1e-4:\n#         return q + 1e3\n\n#     return q\n    \n# def calibrate_signal(signal):\n#     p1,p2 = phase_detector(signal)\n\n#     best_deg, best_score = 1, 1e12\n#     for deg in range(1, 6):\n#         f = partial(try_s, signal, p1, p2, deg)\n#         r = minimize(f, [0.001], method = 'Nelder-Mead')\n#         s = r.x[0]\n\n#         out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n#         x, y = out, signal[out].tolist()\n#         x = x + list(range(p1,p2))\n#         y = y + (signal[p1:p2] * (1 + s)).tolist()\n    \n#         z = np.polyfit(x, y, deg)\n#         p = np.poly1d(z)\n#         q = np.abs(p(x) - y).mean()\n        \n#         if q < best_score:\n#             best_score = q\n#             best_deg = deg\n        \n#         print(deg, q)\n            \n#     z = np.polyfit(x, y, best_deg)\n#     p = np.poly1d(z)\n\n#     return s, x, y, p(x)\n\n# def calibrate_train(signal):\n#     p1,p2 = phase_detector(signal)\n    \n#     best_deg, best_score = 1, 1e12\n#     for deg in range(1, 6):\n#         f = partial(try_s, signal, p1, p2, deg)\n#         r = minimize(f, [0.001], method = 'Nelder-Mead')\n#         s = r.x[0]\n\n#         out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n#         x, y = out, signal[out].tolist()\n#         x = x + list(range(p1,p2))\n#         y = y + (signal[p1:p2] * (1 + s)).tolist()\n    \n#         z = np.polyfit(x, y, deg)\n#         p = np.poly1d(z)\n#         q = np.abs(p(x) - y).mean()\n        \n#         if q < best_score:\n#             best_score = q\n#             best_deg = deg\n            \n#     z = np.polyfit(x, y, best_deg)\n#     p = np.poly1d(z)\n    \n#     return s, p(np.arange(signal.shape[0])), p1, p2\n\n\n# train = pre_train.copy()\n# all_s = []\n# for i in range(len(test_adc_info)):\n#     signal = train[i,:,1:].mean(axis=1)\n#     s, p, p1, p2 = calibrate_train(pre_train[i,:,1:].mean(axis=1))\n#     all_s.append(s)\n        \n# #copy answer 283 times because we predict mean value\n# train_s = np.repeat(np.array(all_s), 283).reshape((len(all_s), 283))        \n# train_sigma = np.ones_like(train_s) * 0.000176","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.787151Z","iopub.execute_input":"2024-09-18T11:39:43.787865Z","iopub.status.idle":"2024-09-18T11:39:43.804878Z","shell.execute_reply.started":"2024-09-18T11:39:43.787787Z","shell.execute_reply":"2024-09-18T11:39:43.803551Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Probably we can accurately estimate sigma from train","metadata":{}},{"cell_type":"code","source":"# n = 0\n# s, x, y, y_new = calibrate_signal(pre_train[n,:,1:].mean(axis=1))\n# plt.scatter(x,y)\n# plt.scatter(x,y_new)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.806459Z","iopub.execute_input":"2024-09-18T11:39:43.806973Z","iopub.status.idle":"2024-09-18T11:39:43.821920Z","shell.execute_reply.started":"2024-09-18T11:39:43.806919Z","shell.execute_reply":"2024-09-18T11:39:43.820280Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"I call the orange line \"starline\". This is probably what we would see if the planet weren't in the way.","metadata":{}},{"cell_type":"markdown","source":"### Making submission","metadata":{}},{"cell_type":"code","source":"# ss = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv')\n\n# preds = train_s.clip(0)\n# sigmas = train_sigma\n# submission = pd.DataFrame(np.concatenate([preds,sigmas], axis=1), columns=ss.columns[1:])\n# submission.index = test_adc_info.index\n# submission.to_csv('submission_2.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.823786Z","iopub.execute_input":"2024-09-18T11:39:43.824255Z","iopub.status.idle":"2024-09-18T11:39:43.834833Z","shell.execute_reply.started":"2024-09-18T11:39:43.824212Z","shell.execute_reply":"2024-09-18T11:39:43.833276Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## [Fork of NeurIPS Ariel 2024 - Starter 5be123](https://www.kaggle.com/code/regisvargas/fork-of-neurips-ariel-2024-starter-5be123)\n\n### [Regis Vargas](https://www.kaggle.com/regisvargas)","metadata":{}},{"cell_type":"markdown","source":"References\n\n1. [Why Did Calibration Lead to a Lower Public Score When Combining Two Kaggle Notebooks?](https://www.kaggle.com/competitions/ariel-data-challenge-2024/discussion/530472)\n\n2. [Fork of NeurIPS Ariel 2024 - Starter 5be123](https://www.kaggle.com/code/regisvargas/fork-of-neurips-ariel-2024-starter-5be123)\n\n3. [NeurIPS Ariel 2024 - Starter withdifferentparametr](https://www.kaggle.com/code/bingyuniu/neurips-ariel-2024-starter-withdifferentparametr)\n\n4. [[UPDATE]Calibrating and Binning Astronomical Data](https://www.kaggle.com/code/gordonyip/update-calibrating-and-binning-astronomical-data)\n\n5. [[UPDATE]Calibrating and Binning Astronomical Data (copy)](https://www.kaggle.com/code/aaronjday/update-calibrating-and-binning-astronomical-data)","metadata":{}},{"cell_type":"markdown","source":"### Initialization\n\nThis competition seems requires strong scientific background and I had lot of confusion during EDA process. Therefore, I just build a simple starter for future coding.\n\n#### Load Library","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import pandas as pd\n# import polars as pl\n# import numpy as np\n# import torch\n# # import torch.nn as nn\n# # import torch.optim as optim\n# # from torch.utils.data import DataLoader, Dataset\n# from tqdm import tqdm\n# import pickle\n# import time\n# import os\n# import pickle\n# import seaborn as sns\n# import scipy.stats\n# from sklearn.model_selection import cross_val_predict\n# from sklearn.linear_model import Ridge\n# from sklearn.metrics import r2_score, mean_squared_error","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.836746Z","iopub.execute_input":"2024-09-18T11:39:43.837306Z","iopub.status.idle":"2024-09-18T11:39:43.847803Z","shell.execute_reply.started":"2024-09-18T11:39:43.837246Z","shell.execute_reply":"2024-09-18T11:39:43.846509Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # Load Meta-Data\n# PATH = \"/kaggle/input/ariel-data-challenge-2024\"\n# train_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_adc_info.csv', \n#                              index_col='planet_id')\n# train_labels = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_labels.csv',\n#                            index_col='planet_id')\n# wavelengths = pd.read_csv(f'{PATH}/wavelengths.csv')\n# axis_info = pd.read_parquet(os.path.join(PATH,'axis_info.parquet'))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.849571Z","iopub.execute_input":"2024-09-18T11:39:43.849993Z","iopub.status.idle":"2024-09-18T11:39:43.861889Z","shell.execute_reply.started":"2024-09-18T11:39:43.849953Z","shell.execute_reply":"2024-09-18T11:39:43.860419Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# train_adc_info['AIRS-CH0_adc_gain'].loc[785834]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.863617Z","iopub.execute_input":"2024-09-18T11:39:43.864074Z","iopub.status.idle":"2024-09-18T11:39:43.880026Z","shell.execute_reply.started":"2024-09-18T11:39:43.864034Z","shell.execute_reply":"2024-09-18T11:39:43.878511Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Pre-Processing\n#### Load Functions","metadata":{}},{"cell_type":"code","source":"# import pywt\n# def wavelet_denoising(data, wavelet = 'db10', sigma=None):\n#     \"\"\"Denoises the signal using SURE wavelet shrinkage with the specified wavelet.\"\"\"\n#     # Criar uma cópia do array para evitar o erro de \"read-only\"\n#     data = np.array(data, copy=True)\n    \n#     # Decompose the signal using discrete wavelet transform\n#     coeffs = pywt.wavedec(data, wavelet)\n    \n#     # Estimate noise level if sigma is not provided\n#     if sigma is None:\n#         # Using the Median Absolute Deviation (MAD) estimator for noise level\n#         sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n#     # Apply thresholding (SURE or hard/soft)\n#     threshold = sigma * np.sqrt(2 * np.log(len(data)))\n#     new_coeffs = [pywt.threshold(c, threshold, mode='soft') for c in coeffs]\n#     # Reconstruct the signal using the modified coefficients\n#     return pywt.waverec(new_coeffs, wavelet)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.884334Z","iopub.execute_input":"2024-09-18T11:39:43.884856Z","iopub.status.idle":"2024-09-18T11:39:43.894621Z","shell.execute_reply.started":"2024-09-18T11:39:43.884779Z","shell.execute_reply":"2024-09-18T11:39:43.893143Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# %%writefile utils.py\n# import pandas as pd\n# import polars as pl\n# import numpy as np\n# from tqdm import tqdm\n# import pickle\n# PATH = \"/kaggle/input/ariel-data-challenge-2024\"\n# cut_inf, cut_sup = 39, 321\n# def load_signal_data(planet_id, dataset, instrument, img_size):\n#     file_path = f'{PATH}/{dataset}/{planet_id}/{instrument}_signal.parquet'\n#     signal = pd.read_parquet(file_path)\n#     if instrument == \"AIRS-CH0\":\n#         signal = signal.values.astype(np.float64).reshape((signal.shape[0], 32, 356))\n#     else:\n#         signal = signal.values.astype(np.float64).reshape((signal.shape[0], 32, 32))\n#     if dataset == 'train':\n#         gain = train_adc_info[instrument+'_adc_gain'].loc[planet_id]\n#         offset = train_adc_info[instrument+'_adc_offset'].loc[planet_id]\n#         signal = ADC_convert(signal, gain, offset)\n#     else:\n#         gain = test_adc_info[instrument+'_adc_gain'].loc[planet_id]\n#         offset = test_adc_info[instrument+'_adc_offset'].loc[planet_id]\n#         signal = ADC_convert(signal, gain, offset)\n#     if instrument == \"AIRS-CH0\":\n#         dt_airs = axis_info['AIRS-CH0-integration_time'].dropna().values\n#         dt_airs[1::2] += 0.1\n#         signal = signal[:, :, cut_inf:cut_sup]\n#     signal = signal.reshape(signal.shape[0], signal.shape[1] * signal.shape[2])\n#     mean_signal = signal.mean(axis=1)\n#     mean_signal = mean_signal / np.linalg.norm(mean_signal)\n#     net_signal = mean_signal[1::2] - mean_signal[0::2]\n#     #return wavelet_denoising(net_signal)\n#     return net_signal\n# def ADC_convert(signal, gain, offset):\n#     signal = signal.astype(np.float64)\n#     signal /= gain\n#     signal += offset\n#     return signal\n# def read_and_preprocess(dataset, planet_ids, instrument = \"AIRS-CH0\"):\n#     \"\"\"Read the files for all planet_ids and extract the time series.\n#     Parameters\n#     dataset: 'train' or 'test'\n#     planet_ids: list of planet ids\n#     instrument: the instrument of observation, 'AIRS-CH0' or 'FGS1', default to 'AIRS-CH0'\n#     Returns\n#     dataframe with one row per planet_id and 67500 values per row for FGS1 and 5624 for AIRS-CH0\n#     \"\"\"\n#     img_size = 1024 if instrument == \"FGS1\" else 32*356\n#     column_num = 67500 if instrument == 'FGS1' else 5625\n#     raw_train = np.full((len(planet_ids), column_num), np.nan, dtype=np.float32)\n#     for i, planet_id in tqdm(list(enumerate(planet_ids))):\n#         raw_train[i] = load_signal_data(planet_id, dataset, instrument, img_size)\n#     return raw_train\n# def feature_engineering(f_raw, a_raw, adc_info, window_size=50, step_size=15):\n#     \"\"\"Create a dataframe with combined features from the raw data, including sliding window and time-series statistics.\n    \n#     Parameters:\n#     f_raw: ndarray of shape (n_planets, 67500)\n#     a_raw: ndarray of shape (n_planets, 5625)\n#     window_size: int, size of the sliding window for time-series statistics\n#     step_size: int, step size for the sliding window\n    \n#     Return value:\n#     df: DataFrame of shape (n_planets, several features)\n#     \"\"\"\n#     f_obscured = f_raw[:, 23500:44000].mean(axis=1)\n#     f_unobscured = (f_raw[:, :20500].mean(axis=1) + f_raw[:, 47000:].mean(axis=1)) / 2\n#     f_relative_reduction = (f_unobscured - f_obscured) / f_unobscured\n#     f_std_dev = f_raw.std(axis=1)\n#     f_signal_to_noise = f_unobscured / f_std_dev\n#     a_obscured = a_raw[:, 1958:3666].mean(axis=1)\n#     a_unobscured = (a_raw[:, :1708].mean(axis=1) + a_raw[:, 3916:].mean(axis=1)) / 2\n#     a_relative_reduction = (a_unobscured - a_obscured) / a_unobscured\n#     a_std_dev = a_raw.std(axis=1)\n#     a_signal_to_noise = a_unobscured / a_std_dev\n#     f_variance = f_raw.var(axis=1)\n#     a_variance = a_raw.var(axis=1)\n    \n#     f_skewness = pd.DataFrame(f_raw).skew(axis=1).values\n#     a_skewness = pd.DataFrame(a_raw).skew(axis=1).values\n#     f_kurtosis = pd.DataFrame(f_raw).kurtosis(axis=1).values\n#     a_kurtosis = pd.DataFrame(a_raw).kurtosis(axis=1).values\n    \n#     f_half_obscured1 = f_raw[:, 20500:23500].mean(axis=1)\n#     f_half_obscured2 = f_raw[:, 44000:47000].mean(axis=1)\n#     f_half_reduction1 = (f_unobscured - f_half_obscured1) / f_unobscured\n#     f_half_reduction2 = (f_unobscured - f_half_obscured2) / f_unobscured\n#     a_half_obscured1 = a_raw[:, 1708:1958].mean(axis=1)\n#     a_half_obscured2 = a_raw[:, 3666:3916].mean(axis=1)\n#     a_half_reduction1 = (a_unobscured - a_half_obscured1) / a_unobscured\n#     a_half_reduction2 = (a_unobscured - a_half_obscured2) / a_unobscured\n#     # Sliding window features\n#     def sliding_window_features(data, window_size, step_size):\n#         features = []\n#         max_index = data.shape[1]\n#         for start in range(0, max_index - window_size + 1, step_size):\n#             end = start + window_size\n#             window = data[:, start:end]\n#             features.append([\n#                 np.mean(window, axis=1),\n#                 np.std(window, axis=1),\n#                 np.min(window, axis=1),\n#                 np.max(window, axis=1)\n#             ])\n#         if features:\n#             return np.vstack(features).T  # Stack vertically and transpose to get the correct shape\n#         else:\n#             return np.empty((data.shape[0], 0))  # Return empty array with correct shape\n    \n#     f_sliding_features = sliding_window_features(f_raw, window_size, step_size)\n#     a_sliding_features = sliding_window_features(a_raw, window_size, step_size)\n#     print(f'f_sliding_features.shape: {f_sliding_features.shape}')\n#     print(f'a_sliding_features.shape: {a_sliding_features.shape}')\n#     df = pd.DataFrame({\n#         'f_relative_reduction': f_relative_reduction,\n#         'f_signal_to_noise': f_signal_to_noise,\n#         'f_variance': f_variance,\n#         'f_skewness': f_skewness,\n#         'f_kurtosis': f_kurtosis,\n#         'a_relative_reduction': a_relative_reduction,\n#         'a_signal_to_noise': a_signal_to_noise,\n#         'a_variance': a_variance,\n#         'a_skewness': a_skewness,\n#         'a_kurtosis': a_kurtosis,\n#         'f_half_reduction1': f_half_reduction1,\n#         'f_half_reduction2': f_half_reduction2,\n#         'a_half_reduction1': a_half_reduction1,\n#         'a_half_reduction2': a_half_reduction2\n#     })\n#     if f_sliding_features.size > 0:\n#         f_sliding_df = pd.DataFrame(f_sliding_features, columns=[f'f_slide_{i}' for i in range(f_sliding_features.shape[1])])\n#         df = pd.concat([df, f_sliding_df], axis=1)\n#     if a_sliding_features.size > 0:\n#         a_sliding_df = pd.DataFrame(a_sliding_features, columns=[f'a_slide_{i}' for i in range(a_sliding_features.shape[1])])\n#         df = pd.concat([df, a_sliding_df], axis=1)\n    \n#     df = pd.concat([df, adc_info.reset_index().iloc[:, 1:6]], axis=1)\n    \n#     return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.896913Z","iopub.execute_input":"2024-09-18T11:39:43.897510Z","iopub.status.idle":"2024-09-18T11:39:43.913398Z","shell.execute_reply.started":"2024-09-18T11:39:43.897456Z","shell.execute_reply":"2024-09-18T11:39:43.911896Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# %%writefile -a utils.py\n\n# def postprocessing(pred_array, index, sigma_pred):\n#     \"\"\"Create a submission dataframe from its components\n    \n#     Parameters:\n#     pred_array: ndarray of shape (n_samples, 283)\n#     index: pandas.Index of length n_samples with name 'planet_id'\n#     sigma_pred: float\n    \n#     Return value:\n#     df: DataFrame of shape (n_samples, 566) with planet_id as index\n#     \"\"\"\n#     return pd.concat([pd.DataFrame(pred_array.clip(0, None), index=index, columns=wavelengths.columns),\n#                       pd.DataFrame(sigma_pred, index=index, columns=[f\"sigma_{i}\" for i in range(1, 284)])],\n#                      axis=1)\n\n# class ParticipantVisibleError(Exception):\n#     pass\n\n# def competition_score(\n#         solution: pd.DataFrame,\n#         submission: pd.DataFrame,\n#         naive_mean: float,\n#         naive_sigma: float,\n#         sigma_true: float,\n#         row_id_column_name='planet_id',\n#     ) -> float:\n#     '''\n#     This is a Gaussian Log Likelihood based metric. For a submission, which contains the predicted mean (x_hat) and variance (x_hat_std),\n#     we calculate the Gaussian Log-likelihood (GLL) value to the provided ground truth (x). We treat each pair of x_hat,\n#     x_hat_std as a 1D gaussian, meaning there will be 283 1D gaussian distributions, hence 283 values for each test spectrum,\n#     the GLL value for one spectrum is the sum of all of them.\n\n#     Inputs:\n#         - solution: Ground Truth spectra (from test set)\n#             - shape: (nsamples, n_wavelengths)\n#         - submission: Predicted spectra and errors (from participants)\n#             - shape: (nsamples, n_wavelengths*2)\n#         naive_mean: (float) mean from the train set.\n#         naive_sigma: (float) standard deviation from the train set.\n#         sigma_true: (float) essentially sets the scale of the outputs.\n#     '''\n\n#     del solution[row_id_column_name]\n#     del submission[row_id_column_name]\n\n#     if submission.min().min() < 0:\n#         raise ParticipantVisibleError('Negative values in the submission')\n#     for col in submission.columns:\n#         if not pd.api.types.is_numeric_dtype(submission[col]):\n#             raise ParticipantVisibleError(f'Submission column {col} must be a number')\n\n#     n_wavelengths = len(solution.columns)\n#     if len(submission.columns) != n_wavelengths*2:\n#         raise ParticipantVisibleError('Wrong number of columns in the submission')\n\n#     y_pred = submission.iloc[:, :n_wavelengths].values\n#     # Set a non-zero minimum sigma pred to prevent division by zero errors.\n#     sigma_pred = np.clip(submission.iloc[:, n_wavelengths:].values, a_min=10**-15, a_max=None)\n#     y_true = solution.values\n\n#     GLL_pred = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred))\n#     GLL_true = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_true, scale=sigma_true * np.ones_like(y_true)))\n#     GLL_mean = np.sum(scipy.stats.norm.logpdf(y_true, loc=naive_mean * np.ones_like(y_true), scale=naive_sigma * np.ones_like(y_true)))\n\n#     submit_score = (GLL_pred - GLL_mean)/(GLL_true - GLL_mean)\n#     return float(np.clip(submit_score, 0.0, 1.0))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.914951Z","iopub.execute_input":"2024-09-18T11:39:43.915437Z","iopub.status.idle":"2024-09-18T11:39:43.932602Z","shell.execute_reply.started":"2024-09-18T11:39:43.915397Z","shell.execute_reply":"2024-09-18T11:39:43.930836Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# exec(open('utils.py', 'r').read())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.934530Z","iopub.execute_input":"2024-09-18T11:39:43.935055Z","iopub.status.idle":"2024-09-18T11:39:43.950019Z","shell.execute_reply.started":"2024-09-18T11:39:43.935009Z","shell.execute_reply":"2024-09-18T11:39:43.948514Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Load Data","metadata":{}},{"cell_type":"code","source":"# %%time\n# if os.path.exists(\"/kaggle/input/adc24-intro-training/f_raw_train.pickle\"):\n#     f_raw_train = np.load('/kaggle/input/adc24-intro-training/f_raw_train.pickle', allow_pickle=True)\n# else:\n#     f_raw_train = read_and_preprocess('train', train_labels.index, 'FGS1')\n#     with open('f_raw_train.pickle', 'wb') as f:\n#         pickle.dump(f_raw_train, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.951686Z","iopub.execute_input":"2024-09-18T11:39:43.952186Z","iopub.status.idle":"2024-09-18T11:39:43.962421Z","shell.execute_reply.started":"2024-09-18T11:39:43.952134Z","shell.execute_reply":"2024-09-18T11:39:43.960902Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# %%time\n# if os.path.exists(\"/kaggle/input/adc24-intro-training/a_raw_train.pickle\"):\n#     a_raw_train = np.load('/kaggle/input/adc24-intro-training/a_raw_train.pickle', allow_pickle=True)\n# else:\n#     a_raw_train = read_and_preprocess('train', train_labels.index)\n#     with open('a_raw_train.pickle', 'wb') as f:\n#         pickle.dump(a_raw_train, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.964232Z","iopub.execute_input":"2024-09-18T11:39:43.964756Z","iopub.status.idle":"2024-09-18T11:39:43.980130Z","shell.execute_reply.started":"2024-09-18T11:39:43.964699Z","shell.execute_reply":"2024-09-18T11:39:43.978617Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"# %%time\n# train = feature_engineering(f_raw_train, a_raw_train, train_adc_info)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.981855Z","iopub.execute_input":"2024-09-18T11:39:43.983001Z","iopub.status.idle":"2024-09-18T11:39:43.993265Z","shell.execute_reply.started":"2024-09-18T11:39:43.982953Z","shell.execute_reply":"2024-09-18T11:39:43.991730Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# train.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:43.994752Z","iopub.execute_input":"2024-09-18T11:39:43.995186Z","iopub.status.idle":"2024-09-18T11:39:44.005763Z","shell.execute_reply.started":"2024-09-18T11:39:43.995145Z","shell.execute_reply":"2024-09-18T11:39:44.004300Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# train = train.iloc[:,:-1]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.007531Z","iopub.execute_input":"2024-09-18T11:39:44.008021Z","iopub.status.idle":"2024-09-18T11:39:44.017543Z","shell.execute_reply.started":"2024-09-18T11:39:44.007979Z","shell.execute_reply":"2024-09-18T11:39:44.016241Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Data Plot","metadata":{}},{"cell_type":"code","source":"# plt.figure(figsize=(6, 2))\n# plt.plot(f_raw_train.mean(axis=0))\n# for time_step in [20500, 23500, 44000, 47000]:\n#     plt.axvline(time_step, color='gray')\n# plt.xlabel('time step')\n# plt.title('FGS1: Overall mean')\n# plt.show()\n\n# plt.figure(figsize=(6, 2))\n# plt.plot(a_raw_train.mean(axis=0))\n# for time_step in [20500, 23500, 44000, 47000]:\n#     plt.axvline(time_step * 11250 // 135000, color='gray')\n# plt.xlabel('time step')\n# plt.title('AIRS-CH0: Overall mean')\n# plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.019169Z","iopub.execute_input":"2024-09-18T11:39:44.019621Z","iopub.status.idle":"2024-09-18T11:39:44.030313Z","shell.execute_reply.started":"2024-09-18T11:39:44.019577Z","shell.execute_reply":"2024-09-18T11:39:44.028971Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# color_array = np.array(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n# plt.scatter(train.a_relative_reduction, train_labels.wl_1, s=15, alpha=0.5,\n#             c=color_array[train_adc_info.star])\n# plt.xlabel('relative signal reduction when planet is in front')\n# plt.ylabel('target')\n# plt.title('Correlation between relative signal reduction and target')\n# # plt.gca().set_aspect('equal')\n# points = [plt.Line2D([0], [0], label=f'star {i}', marker='o', markersize=3,\n#          markeredgecolor=color_array[i], markerfacecolor=color_array[i], linestyle='') for i in range(2)]\n\n# plt.legend(handles=points)\n# plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.031980Z","iopub.execute_input":"2024-09-18T11:39:44.032409Z","iopub.status.idle":"2024-09-18T11:39:44.042539Z","shell.execute_reply.started":"2024-09-18T11:39:44.032366Z","shell.execute_reply":"2024-09-18T11:39:44.041206Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### Model\n#### Rigde Model","metadata":{}},{"cell_type":"code","source":"# model = Ridge(alpha=1e-12)\n\n# oof_pred = cross_val_predict(model, train, train_labels)\n\n# print(f\"# R2 score: {r2_score(train_labels, oof_pred):.4f}\")\n# sigma_pred = mean_squared_error(train_labels, oof_pred, squared=False)\n# print(f\"# Root mean squared error: {sigma_pred:.7f}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.048187Z","iopub.execute_input":"2024-09-18T11:39:44.049152Z","iopub.status.idle":"2024-09-18T11:39:44.054728Z","shell.execute_reply.started":"2024-09-18T11:39:44.049086Z","shell.execute_reply":"2024-09-18T11:39:44.053494Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# oof_df = postprocessing(oof_pred, train_adc_info.index, sigma_pred)\n# display(oof_df)\n\n# gll_score = competition_score(train_labels.copy().reset_index(),\n#                               oof_df.copy().reset_index(),\n#                               naive_mean=train_labels.values.mean(),\n#                               naive_sigma=train_labels.values.std(),\n#                               sigma_true=0.000003)\n# print(f\"# Estimated competition score: {gll_score:.4f}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.056565Z","iopub.execute_input":"2024-09-18T11:39:44.057012Z","iopub.status.idle":"2024-09-18T11:39:44.072264Z","shell.execute_reply.started":"2024-09-18T11:39:44.056951Z","shell.execute_reply":"2024-09-18T11:39:44.071066Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# model.fit(train, train_labels)\n# with open('model.pickle', 'wb') as f:\n#     pickle.dump(model, f)\n# with open('sigma_pred.pickle', 'wb') as f:\n#     pickle.dump(sigma_pred, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.074218Z","iopub.execute_input":"2024-09-18T11:39:44.074678Z","iopub.status.idle":"2024-09-18T11:39:44.085377Z","shell.execute_reply.started":"2024-09-18T11:39:44.074597Z","shell.execute_reply":"2024-09-18T11:39:44.083771Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"# # Load the data\n# test_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/test_adc_info.csv',\n#                            index_col='planet_id')\n# sample_submission = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv',\n#                                 index_col='planet_id')\n# f_raw_test = read_and_preprocess('test', sample_submission.index, 'FGS1')\n# a_raw_test = read_and_preprocess('test', sample_submission.index)\n# test = feature_engineering(f_raw_test, a_raw_test, test_adc_info)\n# test = test.iloc[: , :-1]\n# # Load the model\n# with open('model.pickle', 'rb') as f:\n#     model = pickle.load(f)\n# with open('sigma_pred.pickle', 'rb') as f:\n#     sigma_pred = pickle.load(f)\n\n# # Predict\n# test_pred = model.predict(test)\n\n# # Package into submission file\n# sub_df = sub_df = postprocessing(test_pred,\n#                         test_adc_info.index,\n#                         sigma_pred=np.tile(np.where(test_adc_info[['star']] <= 1, 0.0001555, 0.00085), (1, 283)))\n# display(sub_df)\n# sub_df.to_csv('submission_3.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.087629Z","iopub.execute_input":"2024-09-18T11:39:44.088577Z","iopub.status.idle":"2024-09-18T11:39:44.098695Z","shell.execute_reply.started":"2024-09-18T11:39:44.088529Z","shell.execute_reply":"2024-09-18T11:39:44.097063Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## [AD24[TRAIN-INF]Ridge_AddFE[LB.441]](https://www.kaggle.com/code/hideyukizushi/ad24-train-inf-ridge-addfe-lb-441)\n\n### [yukiZ](https://www.kaggle.com/hideyukizushi)","metadata":{}},{"cell_type":"markdown","source":"### ℹ️ **Info**\n* **forked original great work kernels**\n\n    * https://www.kaggle.com/code/ambrosm/adc24-intro-inference\n    * https://www.kaggle.com/code/hugowjd/neurips-ariel-2024-starter\n    * https://www.kaggle.com/code/xiaocao123/neurips-ariel-2024-starter?scriptVersionId=193156800\n    * https://www.kaggle.com/code/bingyuniu/neurips-ariel-2024-starter-withdifferentparametr\n\n* **2024/08/26 My Additional**\n    * percentile FE add.\n```\nnp.percentile(window, 5, axis=1),\nnp.percentile(window, 10, axis=1),\nnp.percentile(window, 15, axis=1),\nnp.percentile(window, 20, axis=1),\nnp.percentile(window, 25, axis=1),\nnp.percentile(window, 30, axis=1),\nnp.percentile(window, 35, axis=1),\nnp.percentile(window, 40, axis=1),\nnp.percentile(window, 60, axis=1),\nnp.percentile(window, 65, axis=1),\nnp.percentile(window, 70, axis=1),\nnp.percentile(window, 75, axis=1),\nnp.percentile(window, 80, axis=1),\nnp.percentile(window, 85, axis=1),\nnp.percentile(window, 90, axis=1),\nnp.percentile(window, 95, axis=1),\nnp.median(window, axis=1),\nnp.var(window, axis=1),\n```\n\n* **2024/08/29 My Additional**\n    * add FE\n```\nf_sliding_features2 = sliding_window_features(f_raw, 100, 10)\na_sliding_features2 = sliding_window_features(a_raw, 100, 10)\n```","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import pandas as pd\n# import polars as pl\n# import numpy as np\n# import torch\n# # import torch.nn as nn\n# # import torch.optim as optim\n# # from torch.utils.data import DataLoader, Dataset\n# from tqdm import tqdm\n# import pickle\n# import time\n# import os\n# import pickle\n# import seaborn as sns\n# import scipy.stats\n# from sklearn.model_selection import cross_val_predict\n# from sklearn.linear_model import Ridge\n# from sklearn.metrics import r2_score, mean_squared_error\n# from scipy.stats import kurtosis\n# from scipy.stats import skew","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.100470Z","iopub.execute_input":"2024-09-18T11:39:44.101020Z","iopub.status.idle":"2024-09-18T11:39:44.112886Z","shell.execute_reply.started":"2024-09-18T11:39:44.100946Z","shell.execute_reply":"2024-09-18T11:39:44.111437Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# # Load Meta-Data\n# PATH = \"/kaggle/input/ariel-data-challenge-2024\"\n# train_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_adc_info.csv', \n#                              index_col='planet_id')\n# train_labels = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_labels.csv',\n#                            index_col='planet_id')\n# wavelengths = pd.read_csv(f'{PATH}/wavelengths.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.114697Z","iopub.execute_input":"2024-09-18T11:39:44.115212Z","iopub.status.idle":"2024-09-18T11:39:44.132027Z","shell.execute_reply.started":"2024-09-18T11:39:44.115161Z","shell.execute_reply":"2024-09-18T11:39:44.130570Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### Pre-Processing\n#### Load Functions","metadata":{}},{"cell_type":"code","source":"# %%writefile utils.py\n# import pandas as pd\n# import polars as pl\n# import numpy as np\n# from tqdm import tqdm\n# import pickle\n# PATH = \"/kaggle/input/ariel-data-challenge-2024\"\n# def load_signal_data(planet_id, dataset, instrument, img_size):\n#     file_path = f'{PATH}/{dataset}/{planet_id}/{instrument}_signal.parquet'\n#     signal = pl.read_parquet(file_path)\n#     mean_signal = signal.cast(pl.Int32).sum_horizontal().cast(pl.Float32).to_numpy() / img_size # mean over the 32*32 pixels\n#     net_signal = mean_signal[1::2] - mean_signal[0::2]\n#     return net_signal\n\n# def read_and_preprocess(dataset, planet_ids, instrument = \"AIRS-CH0\"):\n#     \"\"\"Read the files for all planet_ids and extract the time series.\n#     Parameters\n#     dataset: 'train' or 'test'\n#     planet_ids: list of planet ids\n#     instrument: the instrument of observation, 'AIRS-CH0' or 'FGS1', default to 'AIRS-CH0'\n#     Returns\n#     dataframe with one row per planet_id and 67500 values per row for FGS1 and 5624 for AIRS-CH0\n#     \"\"\"\n#     img_size = 1024 if instrument == \"FGS1\" else 32*356\n#     column_num = 67500 if instrument == 'FGS1' else 5625\n#     raw_train = np.full((len(planet_ids), column_num), np.nan, dtype=np.float32)\n#     for i, planet_id in tqdm(list(enumerate(planet_ids))):\n#         raw_train[i] = load_signal_data(planet_id, dataset, instrument, img_size)\n#     return raw_train\n\n# def feature_engineering(f_raw, a_raw, adc_info, window_size=60, step_size=15):\n#     \"\"\"Create a dataframe with combined features from the raw data, including sliding window and time-series statistics.\n    \n#     Parameters:\n#     f_raw: ndarray of shape (n_planets, 67500)\n#     a_raw: ndarray of shape (n_planets, 5625)\n#     window_size: int, size of the sliding window for time-series statistics\n#     step_size: int, step size for the sliding window\n    \n#     Return value:\n#     df: DataFrame of shape (n_planets, several features)\n#     \"\"\"\n#     f_obscured = f_raw[:, 23500:44000].mean(axis=1)\n#     f_unobscured = (f_raw[:, :20500].mean(axis=1) + f_raw[:, 47000:].mean(axis=1)) / 2\n#     f_relative_reduction = (f_unobscured - f_obscured) / f_unobscured\n#     f_std_dev = f_raw.std(axis=1)\n#     f_signal_to_noise = f_unobscured / f_std_dev\n\n#     a_obscured = a_raw[:, 1958:3666].mean(axis=1)\n#     a_unobscured = (a_raw[:, :1708].mean(axis=1) + a_raw[:, 3916:].mean(axis=1)) / 2\n#     a_relative_reduction = (a_unobscured - a_obscured) / a_unobscured\n#     a_std_dev = a_raw.std(axis=1)\n#     a_signal_to_noise = a_unobscured / a_std_dev\n\n#     f_variance = f_raw.var(axis=1)\n#     a_variance = a_raw.var(axis=1)\n    \n#     f_skewness = pd.DataFrame(f_raw).skew(axis=1).values\n#     a_skewness = pd.DataFrame(a_raw).skew(axis=1).values\n\n#     f_kurtosis = pd.DataFrame(f_raw).kurtosis(axis=1).values\n#     a_kurtosis = pd.DataFrame(a_raw).kurtosis(axis=1).values\n    \n#     f_half_obscured1 = f_raw[:, 20500:23500].mean(axis=1)\n#     f_half_obscured2 = f_raw[:, 44000:47000].mean(axis=1)\n#     f_half_reduction1 = (f_unobscured - f_half_obscured1) / f_unobscured\n#     f_half_reduction2 = (f_unobscured - f_half_obscured2) / f_unobscured\n\n#     a_half_obscured1 = a_raw[:, 1708:1958].mean(axis=1)\n#     a_half_obscured2 = a_raw[:, 3666:3916].mean(axis=1)\n#     a_half_reduction1 = (a_unobscured - a_half_obscured1) / a_unobscured\n#     a_half_reduction2 = (a_unobscured - a_half_obscured2) / a_unobscured\n\n#     # Sliding window features\n#     def sliding_window_features(data, window_size, step_size):\n#         features = []\n#         max_index = data.shape[1]\n#         for start in range(0, max_index - window_size + 1, step_size):\n#             end = start + window_size\n#             window = data[:, start:end]\n#             features.append([\n#                 np.mean(window, axis=1),\n#                 np.std(window, axis=1),\n#                 np.min(window, axis=1),\n#                 np.max(window, axis=1),\n#                 np.percentile(window, 5, axis=1),\n#                 np.percentile(window, 10, axis=1),\n#                 np.percentile(window, 15, axis=1),\n#                 np.percentile(window, 20, axis=1),\n#                 np.percentile(window, 25, axis=1),\n#                 np.percentile(window, 30, axis=1),\n#                 np.percentile(window, 35, axis=1),\n#                 np.percentile(window, 40, axis=1),\n#                 np.percentile(window, 60, axis=1),\n#                 np.percentile(window, 65, axis=1),\n#                 np.percentile(window, 70, axis=1),\n#                 np.percentile(window, 75, axis=1),\n#                 np.percentile(window, 80, axis=1),\n#                 np.percentile(window, 85, axis=1),\n#                 np.percentile(window, 90, axis=1),\n#                 np.percentile(window, 95, axis=1),\n#                 np.median(window, axis=1),\n#                 np.var(window, axis=1),\n# #                 kurtosis(window, axis=1),\n# #                 skew(window, axis=1),\n#             ])\n#         if features:\n#             return np.vstack(features).T  # Stack vertically and transpose to get the correct shape\n#         else:\n#             return np.empty((data.shape[0], 0))  # Return empty array with correct shape\n    \n#     f_sliding_features = sliding_window_features(f_raw, window_size, step_size)\n#     a_sliding_features = sliding_window_features(a_raw, window_size, step_size)\n    \n#     f_sliding_features2 = sliding_window_features(f_raw, 100, 10)\n#     a_sliding_features2 = sliding_window_features(a_raw, 100, 10)\n\n\n#     print(f'f_sliding_features.shape: {f_sliding_features.shape}')\n#     print(f'a_sliding_features.shape: {a_sliding_features.shape}')\n\n\n#     df = pd.DataFrame({\n#         'f_relative_reduction': f_relative_reduction,\n#         'f_signal_to_noise': f_signal_to_noise,\n#         'f_variance': f_variance,\n#         'f_skewness': f_skewness,\n#         'f_kurtosis': f_kurtosis,\n#         'a_relative_reduction': a_relative_reduction,\n#         'a_signal_to_noise': a_signal_to_noise,\n#         'a_variance': a_variance,\n#         'a_skewness': a_skewness,\n#         'a_kurtosis': a_kurtosis,\n#         'f_half_reduction1': f_half_reduction1,\n#         'f_half_reduction2': f_half_reduction2,\n#         'a_half_reduction1': a_half_reduction1,\n#         'a_half_reduction2': a_half_reduction2\n#     })\n\n\n#     if f_sliding_features.size > 0:\n#         f_sliding_df = pd.DataFrame(f_sliding_features, columns=[f'f_slide_{i}' for i in range(f_sliding_features.shape[1])])\n#         df = pd.concat([df, f_sliding_df], axis=1)\n#     if a_sliding_features.size > 0:\n#         a_sliding_df = pd.DataFrame(a_sliding_features, columns=[f'a_slide_{i}' for i in range(a_sliding_features.shape[1])])\n#         df = pd.concat([df, a_sliding_df], axis=1)\n    \n#     if f_sliding_features2.size > 0:\n#         f_sliding_df = pd.DataFrame(f_sliding_features2, columns=[f'f_slide2_{i}' for i in range(f_sliding_features2.shape[1])])\n#         df = pd.concat([df, f_sliding_df], axis=1)\n#     if a_sliding_features2.size > 0:\n#         a_sliding_df = pd.DataFrame(a_sliding_features2, columns=[f'a_slide2_{i}' for i in range(a_sliding_features2.shape[1])])\n#         df = pd.concat([df, a_sliding_df], axis=1)\n    \n    \n#     df = pd.concat([df, adc_info.reset_index().iloc[:, 1:6]], axis=1)\n    \n#     return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.133901Z","iopub.execute_input":"2024-09-18T11:39:44.134400Z","iopub.status.idle":"2024-09-18T11:39:44.149098Z","shell.execute_reply.started":"2024-09-18T11:39:44.134344Z","shell.execute_reply":"2024-09-18T11:39:44.147444Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# %%writefile -a utils.py\n\n# def postprocessing(pred_array, index, sigma_pred):\n#     \"\"\"Create a submission dataframe from its components\n    \n#     Parameters:\n#     pred_array: ndarray of shape (n_samples, 283)\n#     index: pandas.Index of length n_samples with name 'planet_id'\n#     sigma_pred: float\n    \n#     Return value:\n#     df: DataFrame of shape (n_samples, 566) with planet_id as index\n#     \"\"\"\n#     return pd.concat([pd.DataFrame(pred_array.clip(0, None), index=index, columns=wavelengths.columns),\n#                       pd.DataFrame(sigma_pred, index=index, columns=[f\"sigma_{i}\" for i in range(1, 284)])],\n#                      axis=1)\n\n# class ParticipantVisibleError(Exception):\n#     pass\n\n# def competition_score(\n#         solution: pd.DataFrame,\n#         submission: pd.DataFrame,\n#         naive_mean: float,\n#         naive_sigma: float,\n#         sigma_true: float,\n#         row_id_column_name='planet_id',\n#     ) -> float:\n#     '''\n#     This is a Gaussian Log Likelihood based metric. For a submission, which contains the predicted mean (x_hat) and variance (x_hat_std),\n#     we calculate the Gaussian Log-likelihood (GLL) value to the provided ground truth (x). We treat each pair of x_hat,\n#     x_hat_std as a 1D gaussian, meaning there will be 283 1D gaussian distributions, hence 283 values for each test spectrum,\n#     the GLL value for one spectrum is the sum of all of them.\n\n#     Inputs:\n#         - solution: Ground Truth spectra (from test set)\n#             - shape: (nsamples, n_wavelengths)\n#         - submission: Predicted spectra and errors (from participants)\n#             - shape: (nsamples, n_wavelengths*2)\n#         naive_mean: (float) mean from the train set.\n#         naive_sigma: (float) standard deviation from the train set.\n#         sigma_true: (float) essentially sets the scale of the outputs.\n#     '''\n\n#     del solution[row_id_column_name]\n#     del submission[row_id_column_name]\n\n#     if submission.min().min() < 0:\n#         raise ParticipantVisibleError('Negative values in the submission')\n#     for col in submission.columns:\n#         if not pd.api.types.is_numeric_dtype(submission[col]):\n#             raise ParticipantVisibleError(f'Submission column {col} must be a number')\n\n#     n_wavelengths = len(solution.columns)\n#     if len(submission.columns) != n_wavelengths*2:\n#         raise ParticipantVisibleError('Wrong number of columns in the submission')\n\n#     y_pred = submission.iloc[:, :n_wavelengths].values\n#     # Set a non-zero minimum sigma pred to prevent division by zero errors.\n#     sigma_pred = np.clip(submission.iloc[:, n_wavelengths:].values, a_min=10**-15, a_max=None)\n#     y_true = solution.values\n\n#     GLL_pred = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred))\n#     GLL_true = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_true, scale=sigma_true * np.ones_like(y_true)))\n#     GLL_mean = np.sum(scipy.stats.norm.logpdf(y_true, loc=naive_mean * np.ones_like(y_true), scale=naive_sigma * np.ones_like(y_true)))\n\n#     submit_score = (GLL_pred - GLL_mean)/(GLL_true - GLL_mean)\n#     return float(np.clip(submit_score, 0.0, 1.0))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.151000Z","iopub.execute_input":"2024-09-18T11:39:44.151552Z","iopub.status.idle":"2024-09-18T11:39:44.168531Z","shell.execute_reply.started":"2024-09-18T11:39:44.151495Z","shell.execute_reply":"2024-09-18T11:39:44.167185Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# exec(open('utils.py', 'r').read())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.170123Z","iopub.execute_input":"2024-09-18T11:39:44.170579Z","iopub.status.idle":"2024-09-18T11:39:44.185416Z","shell.execute_reply.started":"2024-09-18T11:39:44.170530Z","shell.execute_reply":"2024-09-18T11:39:44.184242Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Load Data","metadata":{}},{"cell_type":"code","source":"# %%time\n# if os.path.exists(\"/kaggle/input/adc24-intro-training/f_raw_train.pickle\"):\n#     f_raw_train = np.load('/kaggle/input/adc24-intro-training/f_raw_train.pickle', allow_pickle=True)\n# else:\n#     f_raw_train = read_and_preprocess('train', train_labels.index, 'FGS1')\n#     with open('f_raw_train.pickle', 'wb') as f:\n#         pickle.dump(f_raw_train, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.186784Z","iopub.execute_input":"2024-09-18T11:39:44.187243Z","iopub.status.idle":"2024-09-18T11:39:44.198793Z","shell.execute_reply.started":"2024-09-18T11:39:44.187201Z","shell.execute_reply":"2024-09-18T11:39:44.197270Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# %%time\n# if os.path.exists(\"/kaggle/input/adc24-intro-training/a_raw_train.pickle\"):\n#     a_raw_train = np.load('/kaggle/input/adc24-intro-training/a_raw_train.pickle', allow_pickle=True)\n# else:\n#     a_raw_train = read_and_preprocess('train', train_labels.index)\n#     with open('a_raw_train.pickle', 'wb') as f:\n#         pickle.dump(a_raw_train, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.200434Z","iopub.execute_input":"2024-09-18T11:39:44.200918Z","iopub.status.idle":"2024-09-18T11:39:44.213712Z","shell.execute_reply.started":"2024-09-18T11:39:44.200861Z","shell.execute_reply":"2024-09-18T11:39:44.212030Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"# %%time\n# train = feature_engineering(f_raw_train, a_raw_train, train_adc_info)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.215413Z","iopub.execute_input":"2024-09-18T11:39:44.215849Z","iopub.status.idle":"2024-09-18T11:39:44.225739Z","shell.execute_reply.started":"2024-09-18T11:39:44.215781Z","shell.execute_reply":"2024-09-18T11:39:44.224420Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# train.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.227985Z","iopub.execute_input":"2024-09-18T11:39:44.229071Z","iopub.status.idle":"2024-09-18T11:39:44.237145Z","shell.execute_reply.started":"2024-09-18T11:39:44.229009Z","shell.execute_reply":"2024-09-18T11:39:44.235565Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# train = train.iloc[:,:-1]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.239362Z","iopub.execute_input":"2024-09-18T11:39:44.239803Z","iopub.status.idle":"2024-09-18T11:39:44.249832Z","shell.execute_reply.started":"2024-09-18T11:39:44.239744Z","shell.execute_reply":"2024-09-18T11:39:44.248604Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Data Plot","metadata":{}},{"cell_type":"code","source":"# plt.figure(figsize=(6, 2))\n# plt.plot(f_raw_train.mean(axis=0))\n# for time_step in [20500, 23500, 44000, 47000]:\n#     plt.axvline(time_step, color='gray')\n# plt.xlabel('time step')\n# plt.title('FGS1: Overall mean')\n# plt.show()\n\n# plt.figure(figsize=(6, 2))\n# plt.plot(a_raw_train.mean(axis=0))\n# for time_step in [20500, 23500, 44000, 47000]:\n#     plt.axvline(time_step * 11250 // 135000, color='gray')\n# plt.xlabel('time step')\n# plt.title('AIRS-CH0: Overall mean')\n# plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.252170Z","iopub.execute_input":"2024-09-18T11:39:44.252733Z","iopub.status.idle":"2024-09-18T11:39:44.263892Z","shell.execute_reply.started":"2024-09-18T11:39:44.252666Z","shell.execute_reply":"2024-09-18T11:39:44.262055Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# color_array = np.array(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n# plt.scatter(train.a_relative_reduction, train_labels.wl_1, s=15, alpha=0.5,\n#             c=color_array[train_adc_info.star])\n# plt.xlabel('relative signal reduction when planet is in front')\n# plt.ylabel('target')\n# plt.title('Correlation between relative signal reduction and target')\n# # plt.gca().set_aspect('equal')\n# points = [plt.Line2D([0], [0], label=f'star {i}', marker='o', markersize=3,\n#          markeredgecolor=color_array[i], markerfacecolor=color_array[i], linestyle='') for i in range(2)]\n\n# plt.legend(handles=points)\n# plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.265759Z","iopub.execute_input":"2024-09-18T11:39:44.266309Z","iopub.status.idle":"2024-09-18T11:39:44.282024Z","shell.execute_reply.started":"2024-09-18T11:39:44.266255Z","shell.execute_reply":"2024-09-18T11:39:44.280512Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"### Model\n#### Rigde Model","metadata":{}},{"cell_type":"code","source":"# model = Ridge(alpha=1e-12)\n\n# oof_pred = cross_val_predict(model, train, train_labels)\n\n# print(f\"# R2 score: {r2_score(train_labels, oof_pred):.4f}\")\n# sigma_pred = mean_squared_error(train_labels, oof_pred, squared=False)\n# print(f\"# Root mean squared error: {sigma_pred:.7f}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.283599Z","iopub.execute_input":"2024-09-18T11:39:44.284059Z","iopub.status.idle":"2024-09-18T11:39:44.295872Z","shell.execute_reply.started":"2024-09-18T11:39:44.284015Z","shell.execute_reply":"2024-09-18T11:39:44.294279Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# oof_df = postprocessing(oof_pred, train_adc_info.index, sigma_pred)\n# display(oof_df)\n\n# gll_score = competition_score(train_labels.copy().reset_index(),\n#                               oof_df.copy().reset_index(),\n#                               naive_mean=train_labels.values.mean(),\n#                               naive_sigma=train_labels.values.std(),\n#                               sigma_true=0.000003)\n# print(f\"# Estimated competition score: {gll_score:.4f}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.298447Z","iopub.execute_input":"2024-09-18T11:39:44.299144Z","iopub.status.idle":"2024-09-18T11:39:44.309920Z","shell.execute_reply.started":"2024-09-18T11:39:44.299079Z","shell.execute_reply":"2024-09-18T11:39:44.308244Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# model.fit(train, train_labels)\n# with open('model.pickle', 'wb') as f:\n#     pickle.dump(model, f)\n# with open('sigma_pred.pickle', 'wb') as f:\n#     pickle.dump(sigma_pred, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.311491Z","iopub.execute_input":"2024-09-18T11:39:44.311951Z","iopub.status.idle":"2024-09-18T11:39:44.325505Z","shell.execute_reply.started":"2024-09-18T11:39:44.311910Z","shell.execute_reply":"2024-09-18T11:39:44.323952Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"# # Load the data\n# test_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/test_adc_info.csv',\n#                            index_col='planet_id')\n# sample_submission = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv',\n#                                 index_col='planet_id')\n# f_raw_test = read_and_preprocess('test', sample_submission.index, 'FGS1')\n# a_raw_test = read_and_preprocess('test', sample_submission.index)\n# test = feature_engineering(f_raw_test, a_raw_test, test_adc_info)\n# test = test.iloc[: , :-1]\n# # Load the model\n# with open('model.pickle', 'rb') as f:\n#     model = pickle.load(f)\n# with open('sigma_pred.pickle', 'rb') as f:\n#     sigma_pred = pickle.load(f)\n\n# # Predict\n# test_pred = model.predict(test)\n\n# # Package into submission file\n# sub_df = sub_df = postprocessing(test_pred,\n#                         test_adc_info.index,\n#                         sigma_pred=np.tile(np.where(test_adc_info[['star']] <= 1, 0.0001555, 0.00085), (1, 283)))\n# display(sub_df)\n# sub_df.to_csv('submission_4.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.327486Z","iopub.execute_input":"2024-09-18T11:39:44.328075Z","iopub.status.idle":"2024-09-18T11:39:44.345764Z","shell.execute_reply.started":"2024-09-18T11:39:44.328018Z","shell.execute_reply":"2024-09-18T11:39:44.344150Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## [NeurIPS Ariel 2024 - Starter withdifferentparametr](https://www.kaggle.com/code/hideyukizushi/ad24-train-inf-ridge-addfe-lb-441)\n\n### [yu🐂](https://www.kaggle.com/bingyuniu)","metadata":{}},{"cell_type":"markdown","source":"### Initialization\n\nThis competition seems requires strong scientific background and I had lot of confusion during EDA process. Therefore, I just build a simple starter for future coding.\n\n#### Load Library","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import seaborn as sns\n# import pandas as pd\n# import polars as pl\n# import numpy as np\n# import torch\n# # import torch.nn as nn\n# # import torch.optim as optim\n# # from torch.utils.data import DataLoader, Dataset\n# from tqdm import tqdm\n# import pickle\n# import time\n# import os\n# import pickle\n# import seaborn as sns\n# import scipy.stats\n# from sklearn.model_selection import cross_val_predict\n# from sklearn.linear_model import Ridge\n# from sklearn.metrics import r2_score, mean_squared_error","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.355044Z","iopub.execute_input":"2024-09-18T11:39:44.355525Z","iopub.status.idle":"2024-09-18T11:39:44.362311Z","shell.execute_reply.started":"2024-09-18T11:39:44.355483Z","shell.execute_reply":"2024-09-18T11:39:44.360605Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# # Load Meta-Data\n# PATH = \"/kaggle/input/ariel-data-challenge-2024\"\n# train_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_adc_info.csv', \n#                              index_col='planet_id')\n# train_labels = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/train_labels.csv',\n#                            index_col='planet_id')\n# wavelengths = pd.read_csv(f'{PATH}/wavelengths.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.364367Z","iopub.execute_input":"2024-09-18T11:39:44.364855Z","iopub.status.idle":"2024-09-18T11:39:44.374702Z","shell.execute_reply.started":"2024-09-18T11:39:44.364781Z","shell.execute_reply":"2024-09-18T11:39:44.373118Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"### Pre-Processing\n#### Load Functions","metadata":{}},{"cell_type":"code","source":"# %%writefile utils.py\n# import pandas as pd\n# import polars as pl\n# import numpy as np\n# from tqdm import tqdm\n# import pickle\n# PATH = \"/kaggle/input/ariel-data-challenge-2024\"\n# def load_signal_data(planet_id, dataset, instrument, img_size):\n#     file_path = f'{PATH}/{dataset}/{planet_id}/{instrument}_signal.parquet'\n#     signal = pl.read_parquet(file_path)\n#     mean_signal = signal.cast(pl.Int32).sum_horizontal().cast(pl.Float32).to_numpy() / img_size # mean over the 32*32 pixels\n#     net_signal = mean_signal[1::2] - mean_signal[0::2]\n#     return net_signal\n\n# def read_and_preprocess(dataset, planet_ids, instrument = \"AIRS-CH0\"):\n#     \"\"\"Read the files for all planet_ids and extract the time series.\n#     Parameters\n#     dataset: 'train' or 'test'\n#     planet_ids: list of planet ids\n#     instrument: the instrument of observation, 'AIRS-CH0' or 'FGS1', default to 'AIRS-CH0'\n#     Returns\n#     dataframe with one row per planet_id and 67500 values per row for FGS1 and 5624 for AIRS-CH0\n#     \"\"\"\n#     img_size = 1024 if instrument == \"FGS1\" else 32*356\n#     column_num = 67500 if instrument == 'FGS1' else 5625\n#     raw_train = np.full((len(planet_ids), column_num), np.nan, dtype=np.float32)\n#     for i, planet_id in tqdm(list(enumerate(planet_ids))):\n#         raw_train[i] = load_signal_data(planet_id, dataset, instrument, img_size)\n#     return raw_train\n\n# def feature_engineering(f_raw, a_raw, adc_info, window_size=50, step_size=15):\n#     \"\"\"Create a dataframe with combined features from the raw data, including sliding window and time-series statistics.\n    \n#     Parameters:\n#     f_raw: ndarray of shape (n_planets, 67500)\n#     a_raw: ndarray of shape (n_planets, 5625)\n#     window_size: int, size of the sliding window for time-series statistics\n#     step_size: int, step size for the sliding window\n    \n#     Return value:\n#     df: DataFrame of shape (n_planets, several features)\n#     \"\"\"\n#     f_obscured = f_raw[:, 23500:44000].mean(axis=1)\n#     f_unobscured = (f_raw[:, :20500].mean(axis=1) + f_raw[:, 47000:].mean(axis=1)) / 2\n#     f_relative_reduction = (f_unobscured - f_obscured) / f_unobscured\n#     f_std_dev = f_raw.std(axis=1)\n#     f_signal_to_noise = f_unobscured / f_std_dev\n\n#     a_obscured = a_raw[:, 1958:3666].mean(axis=1)\n#     a_unobscured = (a_raw[:, :1708].mean(axis=1) + a_raw[:, 3916:].mean(axis=1)) / 2\n#     a_relative_reduction = (a_unobscured - a_obscured) / a_unobscured\n#     a_std_dev = a_raw.std(axis=1)\n#     a_signal_to_noise = a_unobscured / a_std_dev\n\n#     f_variance = f_raw.var(axis=1)\n#     a_variance = a_raw.var(axis=1)\n    \n#     f_skewness = pd.DataFrame(f_raw).skew(axis=1).values\n#     a_skewness = pd.DataFrame(a_raw).skew(axis=1).values\n\n#     f_kurtosis = pd.DataFrame(f_raw).kurtosis(axis=1).values\n#     a_kurtosis = pd.DataFrame(a_raw).kurtosis(axis=1).values\n    \n#     f_half_obscured1 = f_raw[:, 20500:23500].mean(axis=1)\n#     f_half_obscured2 = f_raw[:, 44000:47000].mean(axis=1)\n#     f_half_reduction1 = (f_unobscured - f_half_obscured1) / f_unobscured\n#     f_half_reduction2 = (f_unobscured - f_half_obscured2) / f_unobscured\n\n#     a_half_obscured1 = a_raw[:, 1708:1958].mean(axis=1)\n#     a_half_obscured2 = a_raw[:, 3666:3916].mean(axis=1)\n#     a_half_reduction1 = (a_unobscured - a_half_obscured1) / a_unobscured\n#     a_half_reduction2 = (a_unobscured - a_half_obscured2) / a_unobscured\n\n#     # Sliding window features\n#     def sliding_window_features(data, window_size, step_size):\n#         features = []\n#         max_index = data.shape[1]\n#         for start in range(0, max_index - window_size + 1, step_size):\n#             end = start + window_size\n#             window = data[:, start:end]\n#             features.append([\n#                 np.mean(window, axis=1),\n#                 np.std(window, axis=1),\n#                 np.min(window, axis=1),\n#                 np.max(window, axis=1)\n#             ])\n#         if features:\n#             return np.vstack(features).T  # Stack vertically and transpose to get the correct shape\n#         else:\n#             return np.empty((data.shape[0], 0))  # Return empty array with correct shape\n    \n#     f_sliding_features = sliding_window_features(f_raw, window_size, step_size)\n#     a_sliding_features = sliding_window_features(a_raw, window_size, step_size)\n\n\n#     print(f'f_sliding_features.shape: {f_sliding_features.shape}')\n#     print(f'a_sliding_features.shape: {a_sliding_features.shape}')\n\n\n#     df = pd.DataFrame({\n#         'f_relative_reduction': f_relative_reduction,\n#         'f_signal_to_noise': f_signal_to_noise,\n#         'f_variance': f_variance,\n#         'f_skewness': f_skewness,\n#         'f_kurtosis': f_kurtosis,\n#         'a_relative_reduction': a_relative_reduction,\n#         'a_signal_to_noise': a_signal_to_noise,\n#         'a_variance': a_variance,\n#         'a_skewness': a_skewness,\n#         'a_kurtosis': a_kurtosis,\n#         'f_half_reduction1': f_half_reduction1,\n#         'f_half_reduction2': f_half_reduction2,\n#         'a_half_reduction1': a_half_reduction1,\n#         'a_half_reduction2': a_half_reduction2\n#     })\n\n\n#     if f_sliding_features.size > 0:\n#         f_sliding_df = pd.DataFrame(f_sliding_features, columns=[f'f_slide_{i}' for i in range(f_sliding_features.shape[1])])\n#         df = pd.concat([df, f_sliding_df], axis=1)\n\n#     if a_sliding_features.size > 0:\n#         a_sliding_df = pd.DataFrame(a_sliding_features, columns=[f'a_slide_{i}' for i in range(a_sliding_features.shape[1])])\n#         df = pd.concat([df, a_sliding_df], axis=1)\n    \n#     df = pd.concat([df, adc_info.reset_index().iloc[:, 1:6]], axis=1)\n    \n#     return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.376986Z","iopub.execute_input":"2024-09-18T11:39:44.377628Z","iopub.status.idle":"2024-09-18T11:39:44.393213Z","shell.execute_reply.started":"2024-09-18T11:39:44.377564Z","shell.execute_reply":"2024-09-18T11:39:44.391410Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# %%writefile -a utils.py\n\n# def postprocessing(pred_array, index, sigma_pred):\n#     \"\"\"Create a submission dataframe from its components\n    \n#     Parameters:\n#     pred_array: ndarray of shape (n_samples, 283)\n#     index: pandas.Index of length n_samples with name 'planet_id'\n#     sigma_pred: float\n    \n#     Return value:\n#     df: DataFrame of shape (n_samples, 566) with planet_id as index\n#     \"\"\"\n#     return pd.concat([pd.DataFrame(pred_array.clip(0, None), index=index, columns=wavelengths.columns),\n#                       pd.DataFrame(sigma_pred, index=index, columns=[f\"sigma_{i}\" for i in range(1, 284)])],\n#                      axis=1)\n\n# class ParticipantVisibleError(Exception):\n#     pass\n\n# def competition_score(\n#         solution: pd.DataFrame,\n#         submission: pd.DataFrame,\n#         naive_mean: float,\n#         naive_sigma: float,\n#         sigma_true: float,\n#         row_id_column_name='planet_id',\n#     ) -> float:\n#     '''\n#     This is a Gaussian Log Likelihood based metric. For a submission, which contains the predicted mean (x_hat) and variance (x_hat_std),\n#     we calculate the Gaussian Log-likelihood (GLL) value to the provided ground truth (x). We treat each pair of x_hat,\n#     x_hat_std as a 1D gaussian, meaning there will be 283 1D gaussian distributions, hence 283 values for each test spectrum,\n#     the GLL value for one spectrum is the sum of all of them.\n\n#     Inputs:\n#         - solution: Ground Truth spectra (from test set)\n#             - shape: (nsamples, n_wavelengths)\n#         - submission: Predicted spectra and errors (from participants)\n#             - shape: (nsamples, n_wavelengths*2)\n#         naive_mean: (float) mean from the train set.\n#         naive_sigma: (float) standard deviation from the train set.\n#         sigma_true: (float) essentially sets the scale of the outputs.\n#     '''\n\n#     del solution[row_id_column_name]\n#     del submission[row_id_column_name]\n\n#     if submission.min().min() < 0:\n#         raise ParticipantVisibleError('Negative values in the submission')\n#     for col in submission.columns:\n#         if not pd.api.types.is_numeric_dtype(submission[col]):\n#             raise ParticipantVisibleError(f'Submission column {col} must be a number')\n\n#     n_wavelengths = len(solution.columns)\n#     if len(submission.columns) != n_wavelengths*2:\n#         raise ParticipantVisibleError('Wrong number of columns in the submission')\n\n#     y_pred = submission.iloc[:, :n_wavelengths].values\n#     # Set a non-zero minimum sigma pred to prevent division by zero errors.\n#     sigma_pred = np.clip(submission.iloc[:, n_wavelengths:].values, a_min=10**-15, a_max=None)\n#     y_true = solution.values\n\n#     GLL_pred = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_pred, scale=sigma_pred))\n#     GLL_true = np.sum(scipy.stats.norm.logpdf(y_true, loc=y_true, scale=sigma_true * np.ones_like(y_true)))\n#     GLL_mean = np.sum(scipy.stats.norm.logpdf(y_true, loc=naive_mean * np.ones_like(y_true), scale=naive_sigma * np.ones_like(y_true)))\n\n#     submit_score = (GLL_pred - GLL_mean)/(GLL_true - GLL_mean)\n#     return float(np.clip(submit_score, 0.0, 1.0))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.395666Z","iopub.execute_input":"2024-09-18T11:39:44.396194Z","iopub.status.idle":"2024-09-18T11:39:44.412849Z","shell.execute_reply.started":"2024-09-18T11:39:44.396145Z","shell.execute_reply":"2024-09-18T11:39:44.411344Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# exec(open('utils.py', 'r').read())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.414677Z","iopub.execute_input":"2024-09-18T11:39:44.415993Z","iopub.status.idle":"2024-09-18T11:39:44.429018Z","shell.execute_reply.started":"2024-09-18T11:39:44.415942Z","shell.execute_reply":"2024-09-18T11:39:44.427528Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"### Load Data","metadata":{}},{"cell_type":"code","source":"# %%time\n# if os.path.exists(\"/kaggle/input/adc24-intro-training/f_raw_train.pickle\"):\n#     f_raw_train = np.load('/kaggle/input/adc24-intro-training/f_raw_train.pickle', allow_pickle=True)\n# else:\n#     f_raw_train = read_and_preprocess('train', train_labels.index, 'FGS1')\n#     with open('f_raw_train.pickle', 'wb') as f:\n#         pickle.dump(f_raw_train, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.430866Z","iopub.execute_input":"2024-09-18T11:39:44.431365Z","iopub.status.idle":"2024-09-18T11:39:44.442524Z","shell.execute_reply.started":"2024-09-18T11:39:44.431310Z","shell.execute_reply":"2024-09-18T11:39:44.440971Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# %%time\n# if os.path.exists(\"/kaggle/input/adc24-intro-training/a_raw_train.pickle\"):\n#     a_raw_train = np.load('/kaggle/input/adc24-intro-training/a_raw_train.pickle', allow_pickle=True)\n# else:\n#     a_raw_train = read_and_preprocess('train', train_labels.index)\n#     with open('a_raw_train.pickle', 'wb') as f:\n#         pickle.dump(a_raw_train, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.444621Z","iopub.execute_input":"2024-09-18T11:39:44.445143Z","iopub.status.idle":"2024-09-18T11:39:44.456704Z","shell.execute_reply.started":"2024-09-18T11:39:44.445088Z","shell.execute_reply":"2024-09-18T11:39:44.455374Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"# %%time\n# train = feature_engineering(f_raw_train, a_raw_train, train_adc_info)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.458301Z","iopub.execute_input":"2024-09-18T11:39:44.458711Z","iopub.status.idle":"2024-09-18T11:39:44.469221Z","shell.execute_reply.started":"2024-09-18T11:39:44.458668Z","shell.execute_reply":"2024-09-18T11:39:44.467805Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# train.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.470674Z","iopub.execute_input":"2024-09-18T11:39:44.471109Z","iopub.status.idle":"2024-09-18T11:39:44.481684Z","shell.execute_reply.started":"2024-09-18T11:39:44.471022Z","shell.execute_reply":"2024-09-18T11:39:44.480179Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# train = train.iloc[:,:-1]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.483926Z","iopub.execute_input":"2024-09-18T11:39:44.484438Z","iopub.status.idle":"2024-09-18T11:39:44.494907Z","shell.execute_reply.started":"2024-09-18T11:39:44.484385Z","shell.execute_reply":"2024-09-18T11:39:44.493567Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"### Data Plot","metadata":{}},{"cell_type":"code","source":"# plt.figure(figsize=(6, 2))\n# plt.plot(f_raw_train.mean(axis=0))\n# for time_step in [20500, 23500, 44000, 47000]:\n#     plt.axvline(time_step, color='gray')\n# plt.xlabel('time step')\n# plt.title('FGS1: Overall mean')\n# plt.show()\n\n# plt.figure(figsize=(6, 2))\n# plt.plot(a_raw_train.mean(axis=0))\n# for time_step in [20500, 23500, 44000, 47000]:\n#     plt.axvline(time_step * 11250 // 135000, color='gray')\n# plt.xlabel('time step')\n# plt.title('AIRS-CH0: Overall mean')\n# plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.497010Z","iopub.execute_input":"2024-09-18T11:39:44.497586Z","iopub.status.idle":"2024-09-18T11:39:44.508880Z","shell.execute_reply.started":"2024-09-18T11:39:44.497531Z","shell.execute_reply":"2024-09-18T11:39:44.507143Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# color_array = np.array(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n# plt.scatter(train.a_relative_reduction, train_labels.wl_1, s=15, alpha=0.5,\n#             c=color_array[train_adc_info.star])\n# plt.xlabel('relative signal reduction when planet is in front')\n# plt.ylabel('target')\n# plt.title('Correlation between relative signal reduction and target')\n# # plt.gca().set_aspect('equal')\n# points = [plt.Line2D([0], [0], label=f'star {i}', marker='o', markersize=3,\n#          markeredgecolor=color_array[i], markerfacecolor=color_array[i], linestyle='') for i in range(2)]\n\n# plt.legend(handles=points)\n# plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.510458Z","iopub.execute_input":"2024-09-18T11:39:44.511014Z","iopub.status.idle":"2024-09-18T11:39:44.527294Z","shell.execute_reply.started":"2024-09-18T11:39:44.510962Z","shell.execute_reply":"2024-09-18T11:39:44.525707Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### Model\n#### Rigde Model","metadata":{}},{"cell_type":"code","source":"# model = Ridge(alpha=1e-12)\n\n# oof_pred = cross_val_predict(model, train, train_labels)\n\n# print(f\"# R2 score: {r2_score(train_labels, oof_pred):.4f}\")\n# sigma_pred = mean_squared_error(train_labels, oof_pred, squared=False)\n# print(f\"# Root mean squared error: {sigma_pred:.7f}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.529186Z","iopub.execute_input":"2024-09-18T11:39:44.529708Z","iopub.status.idle":"2024-09-18T11:39:44.541295Z","shell.execute_reply.started":"2024-09-18T11:39:44.529654Z","shell.execute_reply":"2024-09-18T11:39:44.539906Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# oof_df = postprocessing(oof_pred, train_adc_info.index, sigma_pred)\n# display(oof_df)\n\n# gll_score = competition_score(train_labels.copy().reset_index(),\n#                               oof_df.copy().reset_index(),\n#                               naive_mean=train_labels.values.mean(),\n#                               naive_sigma=train_labels.values.std(),\n#                               sigma_true=0.000003)\n# print(f\"# Estimated competition score: {gll_score:.4f}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.542983Z","iopub.execute_input":"2024-09-18T11:39:44.543430Z","iopub.status.idle":"2024-09-18T11:39:44.551755Z","shell.execute_reply.started":"2024-09-18T11:39:44.543375Z","shell.execute_reply":"2024-09-18T11:39:44.550321Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# model.fit(train, train_labels)\n# with open('model.pickle', 'wb') as f:\n#     pickle.dump(model, f)\n# with open('sigma_pred.pickle', 'wb') as f:\n#     pickle.dump(sigma_pred, f)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.553850Z","iopub.execute_input":"2024-09-18T11:39:44.554316Z","iopub.status.idle":"2024-09-18T11:39:44.565237Z","shell.execute_reply.started":"2024-09-18T11:39:44.554276Z","shell.execute_reply":"2024-09-18T11:39:44.563534Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"# # Load the data\n# test_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/test_adc_info.csv',\n#                            index_col='planet_id')\n# sample_submission = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv',\n#                                 index_col='planet_id')\n# f_raw_test = read_and_preprocess('test', sample_submission.index, 'FGS1')\n# a_raw_test = read_and_preprocess('test', sample_submission.index)\n# test = feature_engineering(f_raw_test, a_raw_test, test_adc_info)\n# test = test.iloc[: , :-1]\n# # Load the model\n# with open('model.pickle', 'rb') as f:\n#     model = pickle.load(f)\n# with open('sigma_pred.pickle', 'rb') as f:\n#     sigma_pred = pickle.load(f)\n\n# # Predict\n# test_pred = model.predict(test)\n\n# # Package into submission file\n# sub_df = sub_df = postprocessing(test_pred,\n#                         test_adc_info.index,\n#                         sigma_pred=np.tile(np.where(test_adc_info[['star']] <= 1, 0.0001555, 0.00085), (1, 283)))\n# display(sub_df)\n# sub_df.to_csv('submission_5.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.567773Z","iopub.execute_input":"2024-09-18T11:39:44.568299Z","iopub.status.idle":"2024-09-18T11:39:44.585123Z","shell.execute_reply.started":"2024-09-18T11:39:44.568258Z","shell.execute_reply":"2024-09-18T11:39:44.583636Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"## [ariel_only_correlation | param upd[LB.517]](https://www.kaggle.com/code/hideyukizushi/ariel-only-correlation-param-upd-lb-517)\n### [yukiZ](https://www.kaggle.com/hideyukizushi)","metadata":{}},{"cell_type":"markdown","source":"### ℹ️ **Info**\n* **forked original great work kernels**\n    * https://www.kaggle.com/code/sergeifironov/ariel-only-correlation\n\n* **2024/09/08 My Changed**\n    * scipy minimize() param & other params update","metadata":{}},{"cell_type":"markdown","source":"---\n---","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport scipy.stats\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport itertools\nfrom scipy.optimize import minimize\nfrom functools import partial\nimport random, os\nfrom astropy.stats import sigma_clip","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:44.587078Z","iopub.execute_input":"2024-09-18T11:39:44.587547Z","iopub.status.idle":"2024-09-18T11:39:48.309027Z","shell.execute_reply.started":"2024-09-18T11:39:44.587506Z","shell.execute_reply":"2024-09-18T11:39:48.307771Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"test_adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/test_adc_info.csv',\n                           index_col='planet_id')\naxis_info = pd.read_parquet('/kaggle/input/ariel-data-challenge-2024/axis_info.parquet')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:48.310720Z","iopub.execute_input":"2024-09-18T11:39:48.311598Z","iopub.status.idle":"2024-09-18T11:39:48.532030Z","shell.execute_reply.started":"2024-09-18T11:39:48.311554Z","shell.execute_reply":"2024-09-18T11:39:48.530646Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"def apply_linear_corr(linear_corr,clean_signal):\n    linear_corr = np.flip(linear_corr, axis=0)\n    for x, y in itertools.product(\n                range(clean_signal.shape[1]), range(clean_signal.shape[2])\n            ):\n        poli = np.poly1d(linear_corr[:, x, y])\n        clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n    return clean_signal\n\ndef clean_dark(signal, dark, dt):\n    dark = np.tile(dark, (signal.shape[0], 1, 1))\n    signal -= dark* dt[:, np.newaxis, np.newaxis]\n    return signal\n\ndef preproc(dataset, adc_info, sensor, binning = 15):\n    cut_inf, cut_sup = 39, 321\n    sensor_sizes_dict = {\"AIRS-CH0\":[[11250, 32, 356], [1, 32, cut_sup-cut_inf]], \"FGS1\":[[135000, 32, 32], [1, 32, 32]]}\n    binned_dict = {\"AIRS-CH0\":[11250 // binning // 2, 282], \"FGS1\":[135000 // binning // 2]}\n    linear_corr_dict = {\"AIRS-CH0\":(6, 32, 356), \"FGS1\":(6, 32, 32)}\n    planet_ids = adc_info.index\n    \n    feats = []\n    for i, planet_id in tqdm(list(enumerate(planet_ids))):\n        signal = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/{planet_id}/{sensor}_signal.parquet').to_numpy()\n        dark_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dark.parquet', engine='pyarrow').to_numpy()\n        dead_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dead.parquet', engine='pyarrow').to_numpy()\n        flat_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/flat.parquet', engine='pyarrow').to_numpy()\n        linear_corr = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/linear_corr.parquet').values.astype(np.float64).reshape(linear_corr_dict[sensor])\n\n        signal = signal.reshape(sensor_sizes_dict[sensor][0]) \n        gain = adc_info[f'{sensor}_adc_gain'].values[i]\n        offset = adc_info[f'{sensor}_adc_offset'].values[i]\n        signal = signal / gain + offset\n        \n        hot = sigma_clip(\n            dark_frame, sigma=8, maxiters=5\n        ).mask\n        \n        if sensor != \"FGS1\":\n            signal = signal[:, :, cut_inf:cut_sup] #11250 * 32 * 282\n            #dt = axis_info['AIRS-CH0-integration_time'].dropna().values\n            dt = np.ones(len(signal))*0.1 \n            dt[1::2] += 4.5 #@bilzard idea\n            linear_corr = linear_corr[:, :, cut_inf:cut_sup]\n            dark_frame = dark_frame[:, cut_inf:cut_sup]\n            dead_frame = dead_frame[:, cut_inf:cut_sup]\n            flat_frame = flat_frame[:, cut_inf:cut_sup]\n            hot = hot[:, cut_inf:cut_sup]\n        else:\n            dt = np.ones(len(signal))*0.1\n            dt[1::2] += 0.1\n            \n        signal = signal.clip(0) #@graySnow idea\n        linear_corr_signal = apply_linear_corr(linear_corr, signal)\n        signal = clean_dark(linear_corr_signal, dark_frame, dt)\n        \n        flat = flat_frame.reshape(sensor_sizes_dict[sensor][1])\n        flat[dead_frame.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n        flat[hot.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n        signal = signal / flat\n        \n        if sensor == \"FGS1\":\n            signal = signal.reshape((sensor_sizes_dict[sensor][0][0], sensor_sizes_dict[sensor][0][1]*sensor_sizes_dict[sensor][0][2]))\n        \n        mean_signal = np.nanmean(signal, axis=1) # mean over the 32*32(FGS1) or 32(CH0) pixels\n        cds_signal = (mean_signal[1::2] - mean_signal[0::2])\n        \n        binned = np.zeros((binned_dict[sensor]))\n        for j in range(cds_signal.shape[0] // binning):\n            binned[j] = cds_signal[j*binning:j*binning+binning].mean(axis=0)\n                   \n        if sensor == \"FGS1\":\n            binned = binned.reshape((binned.shape[0],1))\n            \n        feats.append(binned)\n        \n    return np.stack(feats)\n    \npre_train = np.concatenate([preproc('test', test_adc_info, \"FGS1\", 30*12), preproc('test', test_adc_info, \"AIRS-CH0\", 30)], axis=2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:39:48.533891Z","iopub.execute_input":"2024-09-18T11:39:48.534635Z","iopub.status.idle":"2024-09-18T11:40:03.354983Z","shell.execute_reply.started":"2024-09-18T11:39:48.534582Z","shell.execute_reply":"2024-09-18T11:40:03.353510Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:07<00:00,  7.83s/it]\n100%|██████████| 1/1 [00:06<00:00,  6.92s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### fit polynoms for each sample","metadata":{}},{"cell_type":"code","source":"def phase_detector(signal):\n    phase1, phase2 = None, None\n    best_drop = 0\n    for i in range(50//2,150//2):        \n        t1 = signal[i:i+20//2].max() - signal[i:i+20//2].min()\n        if t1 > best_drop:\n            phase1 = i+(20+5)//2\n            best_drop = t1\n    \n    best_drop = 0\n    for i in range(200//2,250//2):\n        t1 = signal[i:i+20//2].max() - signal[i:i+20//2].min()\n        if t1 > best_drop:\n            phase2 = i-5//2\n            best_drop = t1\n    \n    return phase1, phase2\n\ndef try_s(signal, p1, p2, deg, s):\n    out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n    x, y = out, signal[out].tolist()\n    x = x + list(range(p1,p2))\n\n    y = y + (signal[p1:p2] * (1 + s[0])).tolist()\n    z = np.polyfit(x, y, deg)\n    p = np.poly1d(z)\n    q = np.abs(p(x) - y).mean()\n\n    if s < 1e-4:\n        return q + 1e3\n\n    return q\n    \ndef calibrate_signal(signal):\n    p1,p2 = phase_detector(signal)\n\n    best_deg, best_score = 1, 1e12\n    for deg in range(1, 6):\n        f = partial(try_s, signal, p1, p2, deg)\n        r = minimize(f, [0.001], method = 'Nelder-Mead')\n        s = r.x[0]\n\n        out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n        x, y = out, signal[out].tolist()\n        x = x + list(range(p1,p2))\n        y = y + (signal[p1:p2] * (1 + s)).tolist()\n    \n        z = np.polyfit(x, y, deg)\n        p = np.poly1d(z)\n        q = np.abs(p(x) - y).mean()\n        \n        if q < best_score:\n            best_score = q\n            best_deg = deg\n        \n        print(deg, q)\n            \n    z = np.polyfit(x, y, best_deg)\n    p = np.poly1d(z)\n\n    return s, x, y, p(x)\n\ndef calibrate_train(signal):\n    p1,p2 = phase_detector(signal)\n    \n    best_deg, best_score = 1, 1e12\n    for deg in range(1, 6):\n        f = partial(try_s, signal, p1, p2, deg)\n        r = minimize(f, [0.0001], method = 'Nelder-Mead')\n        s = r.x[0]\n\n        out = list(range(p1-30)) + list(range(p2+30,signal.shape[0]))\n        x, y = out, signal[out].tolist()\n        x = x + list(range(p1,p2))\n        y = y + (signal[p1:p2] * (1 + s)).tolist()\n    \n        z = np.polyfit(x, y, deg)\n        p = np.poly1d(z)\n        q = np.abs(p(x) - y).mean()\n        \n        if q < best_score:\n            best_score = q\n            best_deg = deg\n            \n    z = np.polyfit(x, y, best_deg)\n    p = np.poly1d(z)\n    \n    return s, p(np.arange(signal.shape[0])), p1, p2\n\n\ntrain = pre_train.copy()\nall_s = []\nfor i in range(len(test_adc_info)):\n    signal = train[i,:,1:].mean(axis=1)\n    s, p, p1, p2 = calibrate_train(pre_train[i,:,1:].mean(axis=1))\n    all_s.append(s)\n        \n#copy answer 283 times because we predict mean value\ntrain_s = np.repeat(np.array(all_s), 283).reshape((len(all_s), 283))        \ntrain_sigma = np.ones_like(train_s) * 0.000176","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:03.356489Z","iopub.execute_input":"2024-09-18T11:40:03.356873Z","iopub.status.idle":"2024-09-18T11:40:03.461079Z","shell.execute_reply.started":"2024-09-18T11:40:03.356835Z","shell.execute_reply":"2024-09-18T11:40:03.459740Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"Probably we can accurately estimate sigma from train","metadata":{}},{"cell_type":"code","source":"n = 0\ns, x, y, y_new = calibrate_signal(pre_train[n,:,1:].mean(axis=1))\nplt.scatter(x,y)\nplt.scatter(x,y_new)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:03.462694Z","iopub.execute_input":"2024-09-18T11:40:03.463123Z","iopub.status.idle":"2024-09-18T11:40:03.980637Z","shell.execute_reply.started":"2024-09-18T11:40:03.463080Z","shell.execute_reply":"2024-09-18T11:40:03.979119Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"1 0.07244680006452496\n2 0.07002299921950764\n3 0.06342300208129605\n4 0.06371088493969411\n5 0.06319975127381998\n","output_type":"stream"},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"<matplotlib.collections.PathCollection at 0x7a5cb701e560>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"I call the orange line \"starline\". This is probably what we would see if the planet weren't in the way.","metadata":{}},{"cell_type":"markdown","source":"### Making submission","metadata":{}},{"cell_type":"code","source":"ss = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv')\n\npreds = train_s.clip(0)\nsigmas = train_sigma\nsubmission = pd.DataFrame(np.concatenate([preds,sigmas], axis=1), columns=ss.columns[1:])\nsubmission.index = test_adc_info.index\nsubmission.to_csv('submission_7.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:03.982554Z","iopub.execute_input":"2024-09-18T11:40:03.983043Z","iopub.status.idle":"2024-09-18T11:40:04.025259Z","shell.execute_reply.started":"2024-09-18T11:40:03.982999Z","shell.execute_reply":"2024-09-18T11:40:04.024010Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"## [Ariel Data Challenge 2024](https://www.kaggle.com/code/xiaocao123/ariel-data-challenge-2024)\n### [qianc](https://www.kaggle.com/xiaocao123)","metadata":{}},{"cell_type":"markdown","source":"This notebook is an update of https://www.kaggle.com/code/sergeifironov/ariel-only-correlation\nfrom Sergei Fironov\n\nUpdates :\n- keep 10:22 pixels from the 32 (the image are well centred)\n- Use the derivative for the determination of the beginning and end of the signal during eclipse (idea from Reza R. Choubeh)\n- 'Simplification' of the code for minimize\n- Degree of polyfit <= 4\n- Predictions of test after training Ridge regression with the modelization results (targets predictions with modelization) and the True targets. ","metadata":{}},{"cell_type":"markdown","source":"### Librairies","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# import matplotlib.pyplot as plt\n# import numpy as np\n# from tqdm import tqdm\n# import joblib\n\n# from sklearn.linear_model import Ridge\n# from sklearn.metrics import r2_score, mean_squared_error\n# import itertools\n\n# from scipy.optimize import minimize\n# from scipy import optimize\n\n# from astropy.stats import sigma_clip","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.027063Z","iopub.execute_input":"2024-09-18T11:40:04.027486Z","iopub.status.idle":"2024-09-18T11:40:04.034742Z","shell.execute_reply.started":"2024-09-18T11:40:04.027445Z","shell.execute_reply":"2024-09-18T11:40:04.033105Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# dataset = 'test'\n# adc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/'+f'{dataset}_adc_info.csv',index_col='planet_id')\n# axis_info = pd.read_parquet('/kaggle/input/ariel-data-challenge-2024/axis_info.parquet')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.036748Z","iopub.execute_input":"2024-09-18T11:40:04.037419Z","iopub.status.idle":"2024-09-18T11:40:04.046198Z","shell.execute_reply.started":"2024-09-18T11:40:04.037362Z","shell.execute_reply":"2024-09-18T11:40:04.044744Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"### Calibration","metadata":{}},{"cell_type":"code","source":"# def apply_linear_corr(linear_corr,clean_signal):\n#     linear_corr = np.flip(linear_corr, axis=0)\n#     for x, y in itertools.product(\n#                 range(clean_signal.shape[1]), range(clean_signal.shape[2])\n#             ):\n#         poli = np.poly1d(linear_corr[:, x, y])\n#         clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n#     return clean_signal\n\n# def clean_dark(signal, dark, dt):\n#     dark = np.tile(dark, (signal.shape[0], 1, 1))\n#     signal -= dark* dt[:, np.newaxis, np.newaxis]\n#     return signal\n\n# def preproc(dataset, adc_info, sensor, binning = 15):\n#     cut_inf, cut_sup = 39, 321\n#     sensor_sizes_dict = {\"AIRS-CH0\":[[11250, 32, 356], [1, 32, cut_sup-cut_inf]], \"FGS1\":[[135000, 32, 32], [1, 32, 32]]}\n#     binned_dict = {\"AIRS-CH0\":[11250 // binning // 2, 282], \"FGS1\":[135000 // binning // 2]}\n#     linear_corr_dict = {\"AIRS-CH0\":(6, 32, 356), \"FGS1\":(6, 32, 32)}\n#     planet_ids = adc_info.index\n    \n#     feats = []\n#     for i, planet_id in tqdm(list(enumerate(planet_ids))):\n#         signal = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/{planet_id}/{sensor}_signal.parquet').to_numpy()\n#         dark_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dark.parquet', engine='pyarrow').to_numpy()\n#         dead_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dead.parquet', engine='pyarrow').to_numpy()\n#         flat_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/flat.parquet', engine='pyarrow').to_numpy()\n#         linear_corr = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/linear_corr.parquet').values.astype(np.float64).reshape(linear_corr_dict[sensor])\n\n#         signal = signal.reshape(sensor_sizes_dict[sensor][0]) \n#         gain = adc_info[f'{sensor}_adc_gain'].values[i]\n#         offset = adc_info[f'{sensor}_adc_offset'].values[i]\n#         signal = signal / gain + offset\n        \n#         hot = sigma_clip(\n#             dark_frame, sigma=5, maxiters=5\n#         ).mask\n        \n#         if sensor != \"FGS1\":\n#             signal = signal[:, :, cut_inf:cut_sup] \n#             dt = np.ones(len(signal))*0.1 \n#             dt[1::2] += 4.5 #@bilzard idea\n#             linear_corr = linear_corr[:, :, cut_inf:cut_sup]\n#             dark_frame = dark_frame[:, cut_inf:cut_sup]\n#             dead_frame = dead_frame[:, cut_inf:cut_sup]\n#             flat_frame = flat_frame[:, cut_inf:cut_sup]\n#             hot = hot[:, cut_inf:cut_sup]\n#         else:\n#             dt = np.ones(len(signal))*0.1\n#             dt[1::2] += 0.1\n            \n#         signal = signal.clip(0) #@graySnow idea\n#         linear_corr_signal = apply_linear_corr(linear_corr, signal)\n#         signal = clean_dark(linear_corr_signal, dark_frame, dt)\n        \n#         flat = flat_frame.reshape(sensor_sizes_dict[sensor][1])\n#         flat[dead_frame.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n#         flat[hot.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n#         signal = signal / flat\n        \n        \n#         if sensor == \"FGS1\":\n#             signal = signal[:,10:22,10:22] # **** updates ****\n#             signal = signal.reshape(sensor_sizes_dict[sensor][0][0],144) # # **** updates ****\n\n#         if sensor != \"FGS1\":\n#             signal = signal[:,10:22,:] # **** updates ****\n\n#         mean_signal = np.nanmean(signal, axis=1) \n#         cds_signal = (mean_signal[1::2] - mean_signal[0::2])\n        \n#         binned = np.zeros((binned_dict[sensor]))\n#         for j in range(cds_signal.shape[0] // binning):\n#             binned[j] = cds_signal[j*binning:j*binning+binning].mean(axis=0) \n                   \n#         if sensor == \"FGS1\":\n#             binned = binned.reshape((binned.shape[0],1))\n        \n#         feats.append(binned)\n        \n#     return np.stack(feats)\n    \n# pre_train = np.concatenate([preproc(f'{dataset}', adc_info, \"FGS1\", 30*12), preproc(f'{dataset}', adc_info, \"AIRS-CH0\", 30)], axis=2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.048186Z","iopub.execute_input":"2024-09-18T11:40:04.048731Z","iopub.status.idle":"2024-09-18T11:40:04.061996Z","shell.execute_reply.started":"2024-09-18T11:40:04.048677Z","shell.execute_reply":"2024-09-18T11:40:04.060629Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"### Modelization","metadata":{}},{"cell_type":"code","source":"# def phase_detector(signal):\n    \n#     MIN = np.argmin(signal[30:140])+30\n#     signal1 = signal[:MIN ]\n#     signal2 = signal[MIN :]\n\n#     first_derivative1 = np.gradient(signal1)\n#     first_derivative1 /= first_derivative1.max()\n#     first_derivative2 = np.gradient(signal2)\n#     first_derivative2 /= first_derivative2.max()\n\n#     phase1 = np.argmin(first_derivative1)\n#     phase2 = np.argmax(first_derivative2) + MIN\n\n#     return phase1, phase2\n    \n# def objective(s):\n    \n#     best_q = 1e10\n#     for i in range(4) :\n#         delta = 2\n#         x = list(range(signal.shape[0]-delta*4))\n#         y = signal[:p1-delta].tolist() + (signal[p1+delta:p2 - delta] * (1 + s)).tolist() + signal[p2+delta:].tolist()\n        \n#         z = np.polyfit(x, y, deg=i)\n#         p = np.poly1d(z)\n#         q = np.abs(p(x) - y).mean()\n    \n#     if q < best_q :\n#         best_q = q\n    \n#     return q\n\n\n# all_s = []\n# for i in tqdm(range(len(adc_info))):\n    \n#     signal = pre_train[i,:,1:].mean(axis=1)\n#     p1,p2 = phase_detector(signal)\n \n#     r = minimize(\n#                 objective,\n#                 [0.0001],\n#                 method= 'Nelder-Mead'\n#                   )\n#     s = r.x[0]\n#     all_s.append(s)\n    \n# all_s = np.repeat(np.array(all_s), 283).reshape((len(all_s), 283))        ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.063468Z","iopub.execute_input":"2024-09-18T11:40:04.063990Z","iopub.status.idle":"2024-09-18T11:40:04.080712Z","shell.execute_reply.started":"2024-09-18T11:40:04.063938Z","shell.execute_reply":"2024-09-18T11:40:04.079390Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"### Predictions with Ridge model","metadata":{}},{"cell_type":"code","source":"# pd.DataFrame(all_s)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.082596Z","iopub.execute_input":"2024-09-18T11:40:04.083098Z","iopub.status.idle":"2024-09-18T11:40:04.093062Z","shell.execute_reply.started":"2024-09-18T11:40:04.083046Z","shell.execute_reply":"2024-09-18T11:40:04.091280Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# model = joblib.load(\"/kaggle/input/adc24-meta-model-ridge/model_ridge_10_22_delta2.joblib\")\n# pred = model.predict(all_s)\n# pd.DataFrame(pred)\n# import pickle\n# with open('/kaggle/input/ad24-train-inf-ridge-addfe-lb-441/model.pickle', 'rb') as f:\n#     model = pickle.load(f)\n# pred = model.predict(all_s)\n# pd.DataFrame(pred)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.095012Z","iopub.execute_input":"2024-09-18T11:40:04.095512Z","iopub.status.idle":"2024-09-18T11:40:04.105704Z","shell.execute_reply.started":"2024-09-18T11:40:04.095466Z","shell.execute_reply":"2024-09-18T11:40:04.104096Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"# ss = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv')\n# sigma = np.ones_like(all_s) * 0.000145 \n# pred = all_s.clip(0) \n# submission = pd.DataFrame(np.concatenate([pred,sigma], axis=1), columns=ss.columns[1:])\n# submission.index = adc_info.index\n# submission.to_csv('submission_8.csv')\n# submission\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.108176Z","iopub.execute_input":"2024-09-18T11:40:04.108649Z","iopub.status.idle":"2024-09-18T11:40:04.118622Z","shell.execute_reply.started":"2024-09-18T11:40:04.108608Z","shell.execute_reply":"2024-09-18T11:40:04.117355Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"## [LB=0.545](https://www.kaggle.com/code/xiaocao123/lb-0-545)\n### [qianc](https://www.kaggle.com/xiaocao123)","metadata":{}},{"cell_type":"markdown","source":"#### Notebook from https://www.kaggle.com/code/vyacheslavbolotin/ariel-ensemble-of-solutions\n#### If it is useful to you, please give your like.\n\n#### Below is the link to my other notebook, which is also the first sharer.\n\n#### https://www.kaggle.com/code/xiaocao123/ariel-data-challenge-2024","metadata":{}},{"cell_type":"markdown","source":"This notebook is an update of https://www.kaggle.com/code/sergeifironov/ariel-only-correlation\nfrom Sergei Fironov\n\nUpdates :\n- keep 10:22 pixels from the 32 (the image are well centred)\n- Use the derivative for the determination of the beginning and end of the signal during eclipse (idea from Reza R. Choubeh)\n- 'Simplification' of the code for minimize\n- Degree of polyfit <= 4\n- Predictions of test after training Ridge regression with the modelization results (targets predictions with modelization) and the True targets. ","metadata":{}},{"cell_type":"markdown","source":"### Librairies","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nimport joblib\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport itertools\n\nfrom scipy.optimize import minimize\nfrom scipy import optimize\n\nfrom astropy.stats import sigma_clip","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.128552Z","iopub.execute_input":"2024-09-18T11:40:04.129023Z","iopub.status.idle":"2024-09-18T11:40:04.137572Z","shell.execute_reply.started":"2024-09-18T11:40:04.128982Z","shell.execute_reply":"2024-09-18T11:40:04.135741Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"dataset = 'test'\nadc_info = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/'+f'{dataset}_adc_info.csv',index_col='planet_id')\naxis_info = pd.read_parquet('/kaggle/input/ariel-data-challenge-2024/axis_info.parquet')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.139578Z","iopub.execute_input":"2024-09-18T11:40:04.140085Z","iopub.status.idle":"2024-09-18T11:40:04.165678Z","shell.execute_reply.started":"2024-09-18T11:40:04.140032Z","shell.execute_reply":"2024-09-18T11:40:04.164320Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"def apply_linear_corr(linear_corr,clean_signal):\n    linear_corr = np.flip(linear_corr, axis=0)\n    for x, y in itertools.product(\n                range(clean_signal.shape[1]), range(clean_signal.shape[2])\n            ):\n        poli = np.poly1d(linear_corr[:, x, y])\n        clean_signal[:, x, y] = poli(clean_signal[:, x, y])\n    return clean_signal\n\ndef clean_dark(signal, dark, dt):\n    dark = np.tile(dark, (signal.shape[0], 1, 1))\n    signal -= dark* dt[:, np.newaxis, np.newaxis]\n    return signal\n\ndef preproc(dataset, adc_info, sensor, binning = 15):\n    cut_inf, cut_sup = 39, 321\n    sensor_sizes_dict = {\"AIRS-CH0\":[[11250, 32, 356], [1, 32, cut_sup-cut_inf]], \"FGS1\":[[135000, 32, 32], [1, 32, 32]]}\n    binned_dict = {\"AIRS-CH0\":[11250 // binning // 2, 282], \"FGS1\":[135000 // binning // 2]}\n    linear_corr_dict = {\"AIRS-CH0\":(6, 32, 356), \"FGS1\":(6, 32, 32)}\n    planet_ids = adc_info.index\n    \n    feats = []\n    for i, planet_id in tqdm(list(enumerate(planet_ids))):\n        signal = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/{planet_id}/{sensor}_signal.parquet').to_numpy()\n        dark_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dark.parquet', engine='pyarrow').to_numpy()\n        dead_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/dead.parquet', engine='pyarrow').to_numpy()\n        flat_frame = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/flat.parquet', engine='pyarrow').to_numpy()\n        linear_corr = pd.read_parquet(f'/kaggle/input/ariel-data-challenge-2024/{dataset}/' + str(planet_id) + '/' + sensor + '_calibration/linear_corr.parquet').values.astype(np.float64).reshape(linear_corr_dict[sensor])\n\n        signal = signal.reshape(sensor_sizes_dict[sensor][0]) \n        gain = adc_info[f'{sensor}_adc_gain'].values[i]\n        offset = adc_info[f'{sensor}_adc_offset'].values[i]\n        signal = signal / gain + offset\n        \n        hot = sigma_clip(\n            dark_frame, sigma=5, maxiters=5\n        ).mask\n        \n        if sensor != \"FGS1\":\n            signal = signal[:, :, cut_inf:cut_sup] \n            dt = np.ones(len(signal))*0.1 \n            dt[1::2] += 4.5 #@bilzard idea\n            linear_corr = linear_corr[:, :, cut_inf:cut_sup]\n            dark_frame = dark_frame[:, cut_inf:cut_sup]\n            dead_frame = dead_frame[:, cut_inf:cut_sup]\n            flat_frame = flat_frame[:, cut_inf:cut_sup]\n            hot = hot[:, cut_inf:cut_sup]\n        else:\n            dt = np.ones(len(signal))*0.1\n            dt[1::2] += 0.1\n            \n        signal = signal.clip(0) #@graySnow idea\n        linear_corr_signal = apply_linear_corr(linear_corr, signal)\n        signal = clean_dark(linear_corr_signal, dark_frame, dt)\n        \n        flat = flat_frame.reshape(sensor_sizes_dict[sensor][1])\n        flat[dead_frame.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n        flat[hot.reshape(sensor_sizes_dict[sensor][1])] = np.nan\n        signal = signal / flat\n        \n        \n        if sensor == \"FGS1\":\n            signal = signal[:,10:22,10:22] # **** updates ****\n            signal = signal.reshape(sensor_sizes_dict[sensor][0][0],144) # # **** updates ****\n\n        if sensor != \"FGS1\":\n            signal = signal[:,10:22,:] # **** updates ****\n\n        mean_signal = np.nanmean(signal, axis=1) \n        cds_signal = (mean_signal[1::2] - mean_signal[0::2])\n        \n        binned = np.zeros((binned_dict[sensor]))\n        for j in range(cds_signal.shape[0] // binning):\n            binned[j] = cds_signal[j*binning:j*binning+binning].mean(axis=0) \n                   \n        if sensor == \"FGS1\":\n            binned = binned.reshape((binned.shape[0],1))\n        \n        feats.append(binned)\n        \n    return np.stack(feats)\n    \npre_train = np.concatenate([preproc(f'{dataset}', adc_info, \"FGS1\", 30*12), preproc(f'{dataset}', adc_info, \"AIRS-CH0\", 30)], axis=2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:04.167471Z","iopub.execute_input":"2024-09-18T11:40:04.167893Z","iopub.status.idle":"2024-09-18T11:40:14.584866Z","shell.execute_reply.started":"2024-09-18T11:40:04.167845Z","shell.execute_reply":"2024-09-18T11:40:14.583492Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":80,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:05<00:00,  5.31s/it]\n100%|██████████| 1/1 [00:05<00:00,  5.06s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Modelization","metadata":{}},{"cell_type":"code","source":"def phase_detector(signal):\n    \n    MIN = np.argmin(signal[30:140])+30\n    signal1 = signal[:MIN ]\n    signal2 = signal[MIN :]\n\n    first_derivative1 = np.gradient(signal1)\n    first_derivative1 /= first_derivative1.max()\n    first_derivative2 = np.gradient(signal2)\n    first_derivative2 /= first_derivative2.max()\n\n    phase1 = np.argmin(first_derivative1)\n    phase2 = np.argmax(first_derivative2) + MIN\n\n    return phase1, phase2\n    \ndef objective(s):\n    \n    best_q = 1e10\n    for i in range(4) :\n        delta = 2\n        x = list(range(signal.shape[0]-delta*4))\n        y = signal[:p1-delta].tolist() + (signal[p1+delta:p2 - delta] * (1 + s)).tolist() + signal[p2+delta:].tolist()\n        \n        z = np.polyfit(x, y, deg=i)\n        p = np.poly1d(z)\n        q = np.abs(p(x) - y).mean()\n    \n    if q < best_q :\n        best_q = q\n    \n    return q\n\n\nall_s = []\nfor i in tqdm(range(len(adc_info))):\n    \n    signal = pre_train[i,:,1:].mean(axis=1)\n    p1,p2 = phase_detector(signal)\n \n    r = minimize(\n                objective,\n                [0.0001],\n                method= 'Nelder-Mead'\n                  )\n    s = r.x[0]\n    all_s.append(s)\n    \nall_s = np.repeat(np.array(all_s), 283).reshape((len(all_s), 283))        ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:14.586359Z","iopub.execute_input":"2024-09-18T11:40:14.586698Z","iopub.status.idle":"2024-09-18T11:40:14.654972Z","shell.execute_reply.started":"2024-09-18T11:40:14.586663Z","shell.execute_reply":"2024-09-18T11:40:14.653743Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"100%|██████████| 1/1 [00:00<00:00, 20.36it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Predictions with Ridge model","metadata":{}},{"cell_type":"code","source":"# pd.DataFrame(all_s)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:14.656559Z","iopub.execute_input":"2024-09-18T11:40:14.656975Z","iopub.status.idle":"2024-09-18T11:40:14.663134Z","shell.execute_reply.started":"2024-09-18T11:40:14.656936Z","shell.execute_reply":"2024-09-18T11:40:14.661419Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# model = joblib.load(\"/kaggle/input/adc24-meta-model-ridge/model_ridge_10_22_delta2.joblib\")\n# pred = model.predict(all_s)\n# pd.DataFrame(pred)\n# import pickle\n# with open('/kaggle/input/ad24-train-inf-ridge-addfe-lb-441/model.pickle', 'rb') as f:\n#     model = pickle.load(f)\n# pred = model.predict(all_s)\n# pd.DataFrame(pred)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:14.664795Z","iopub.execute_input":"2024-09-18T11:40:14.665453Z","iopub.status.idle":"2024-09-18T11:40:14.676286Z","shell.execute_reply.started":"2024-09-18T11:40:14.665372Z","shell.execute_reply":"2024-09-18T11:40:14.674824Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"ss = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv')\nsigma = np.ones_like(all_s) * 0.0001422 \npred = all_s.clip(0) \nsubmission = pd.DataFrame(np.concatenate([pred,sigma], axis=1), columns=ss.columns[1:])\nsubmission.index = adc_info.index\nsubmission.to_csv('submission_91.csv')\nsubmission","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:14.678165Z","iopub.execute_input":"2024-09-18T11:40:14.678746Z","iopub.status.idle":"2024-09-18T11:40:14.753101Z","shell.execute_reply.started":"2024-09-18T11:40:14.678689Z","shell.execute_reply":"2024-09-18T11:40:14.751896Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"               wl_1      wl_2      wl_3      wl_4      wl_5      wl_6  \\\nplanet_id                                                               \n499191466  0.002725  0.002725  0.002725  0.002725  0.002725  0.002725   \n\n               wl_7      wl_8      wl_9     wl_10  ...  sigma_274  sigma_275  \\\nplanet_id                                          ...                         \n499191466  0.002725  0.002725  0.002725  0.002725  ...   0.000142   0.000142   \n\n           sigma_276  sigma_277  sigma_278  sigma_279  sigma_280  sigma_281  \\\nplanet_id                                                                     \n499191466   0.000142   0.000142   0.000142   0.000142   0.000142   0.000142   \n\n           sigma_282  sigma_283  \nplanet_id                        \n499191466   0.000142   0.000142  \n\n[1 rows x 566 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wl_1</th>\n      <th>wl_2</th>\n      <th>wl_3</th>\n      <th>wl_4</th>\n      <th>wl_5</th>\n      <th>wl_6</th>\n      <th>wl_7</th>\n      <th>wl_8</th>\n      <th>wl_9</th>\n      <th>wl_10</th>\n      <th>...</th>\n      <th>sigma_274</th>\n      <th>sigma_275</th>\n      <th>sigma_276</th>\n      <th>sigma_277</th>\n      <th>sigma_278</th>\n      <th>sigma_279</th>\n      <th>sigma_280</th>\n      <th>sigma_281</th>\n      <th>sigma_282</th>\n      <th>sigma_283</th>\n    </tr>\n    <tr>\n      <th>planet_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>499191466</th>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>0.002725</td>\n      <td>...</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n      <td>0.000142</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 566 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# ss = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv')\n# sigma = np.ones_like(all_s) * 0.0001400\n# pred = all_s.clip(0) \n# submission = pd.DataFrame(np.concatenate([pred,sigma], axis=1), columns=ss.columns[1:])\n# submission.index = adc_info.index\n# submission.to_csv('submission_92.csv')\n# submission","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:14.754686Z","iopub.execute_input":"2024-09-18T11:40:14.755108Z","iopub.status.idle":"2024-09-18T11:40:14.760512Z","shell.execute_reply.started":"2024-09-18T11:40:14.755070Z","shell.execute_reply":"2024-09-18T11:40:14.759280Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# ss = pd.read_csv('/kaggle/input/ariel-data-challenge-2024/sample_submission.csv')\n# sigma = np.ones_like(all_s) * 0.0001450\n# pred = all_s.clip(0) \n# submission = pd.DataFrame(np.concatenate([pred,sigma], axis=1), columns=ss.columns[1:])\n# submission.index = adc_info.index\n# submission.to_csv('submission_93.csv')\n# submission","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:14.762633Z","iopub.execute_input":"2024-09-18T11:40:14.763064Z","iopub.status.idle":"2024-09-18T11:40:14.777661Z","shell.execute_reply.started":"2024-09-18T11:40:14.763024Z","shell.execute_reply":"2024-09-18T11:40:14.776205Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble of solutions","metadata":{}},{"cell_type":"code","source":"# - option 21 -> LB=0.544 work (7,8) + weight (0.03+0.97)\n# - option 22 -> LB=0.544 work (7,8) + weight (0.035+0.965)\n# - option 23 -> LB=0.544 work (7,8) + weight (0.026+0.974)\n# - option 24 -> LB=0.544 work (7,8) + weight (0.032+0.968)\n# - option 25 -> LB=0.544 work (7,8) + weight (0.031+0.969)\n# - option 26 -> LB=0.544 work (7,8) + weight (0.028+0.972)\n# - option 27 -> LB=**0.544** work (7,8) + weight (0.0305+0.9695)\n# - option 28 -> LB=0.544 work (7,8) + weight (0.0290+0.9710)\n# - option 29 -> LB=0.54? work (7,8) + weight (0.0302+0.9698)\n\n# some rezults\n# * option.21 < option.28 < **option.27**\n\n# best option:\n# - option 27 -> LB=**0.544** work (7,8) + weight (0.0305+0.9695), **option.27**, **version 52** \n\n# current option:\n# - option 33 -> LB=0.54? work (7, 9.1, 9.2, 9.3)\n# - option 34 -> LB=0.54? work (7,9) + weight (0.0298+0.9702)\n# - option 35 -> LB=0.54? work (7,9) + weight (0.0302+0.9698)\n\n# next option: \n# - option 30 -> LB=0.54? work (7,8) + weight (0.0295+0.9705)\n# - option 31 -> LB=0.54? work (1,8) + weights\n# - option 32 -> LB=0.54? work (2,8) + weights\n\n# The copyright holder of the eighth notebook from the list specifies his work with the line \n# sigma = np.ones_like(all_s) * 0.0001422 and shows the rise to the leaderboard. \n# Let this be the ninth work on our list!","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:14.779784Z","iopub.execute_input":"2024-09-18T11:40:14.780327Z","iopub.status.idle":"2024-09-18T11:40:14.790016Z","shell.execute_reply.started":"2024-09-18T11:40:14.780257Z","shell.execute_reply":"2024-09-18T11:40:14.788652Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"if LAUNCH_VARIANT == 'option 33':\n    df_solution_x = pd.read_csv('submission_7.csv')\n    df_solution_7 = pd.read_csv('submission_7.csv')\n    df_solution_91 = pd.read_csv('submission_91.csv')\n    df_solution_92 = pd.read_csv('submission_92.csv')\n    df_solution_93 = pd.read_csv('submission_93.csv')\n    df_solution_7 = df_solution_7.map(lambda x:x*0.03)\n    df_solution_91 = df_solution_91.map(lambda x:x*0.77)\n    df_solution_92 = df_solution_92.map(lambda x:x*0.10)\n    df_solution_93 = df_solution_93.map(lambda x:x*0.10)\n    df_temp = df_solution_7.add(df_solution_91).add(df_solution_92).add(df_solution_93)\n    df_submission = df_temp.map(lambda x:x)\n    df_submission['planet_id'] = df_solution_x['planet_id']\n    \nelif LAUNCH_VARIANT == 'option 34':\n    df_solution_x = pd.read_csv('submission_7.csv')\n    df_solution_7 = pd.read_csv('submission_7.csv')\n    df_solution_9 = pd.read_csv('submission_91.csv')\n    df_solution_7 = df_solution_7.map(lambda x:x*0.0298)\n    df_solution_9 = df_solution_9.map(lambda x:x*0.9702)\n    df_temp = df_solution_7.add(df_solution_9)\n    df_submission = df_temp.map(lambda x:x)\n    df_submission['planet_id'] = df_solution_x['planet_id']\n    \nelif LAUNCH_VARIANT == 'option 35':\n    df_solution_x = pd.read_csv('submission_7.csv')\n    df_solution_7 = pd.read_csv('submission_7.csv')\n    df_solution_9 = pd.read_csv('submission_91.csv')\n    df_solution_7 = df_solution_7.map(lambda x:x*0.04)\n    df_solution_9 = df_solution_9.map(lambda x:x*0.97)\n    df_temp = df_solution_7.add(df_solution_9)\n    df_submission = df_temp.map(lambda x:x)\n    df_submission['planet_id'] = df_solution_x['planet_id']","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:40:14.791954Z","iopub.execute_input":"2024-09-18T11:40:14.793122Z","iopub.status.idle":"2024-09-18T11:40:14.988125Z","shell.execute_reply.started":"2024-09-18T11:40:14.793047Z","shell.execute_reply":"2024-09-18T11:40:14.986889Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv('submission.csv', index=False, float_format='%.7f')\ndf_submission","metadata":{"execution":{"iopub.status.busy":"2024-09-18T11:40:14.989639Z","iopub.execute_input":"2024-09-18T11:40:14.990500Z","iopub.status.idle":"2024-09-18T11:40:15.024725Z","shell.execute_reply.started":"2024-09-18T11:40:14.990455Z","shell.execute_reply":"2024-09-18T11:40:15.023295Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"   planet_id      wl_1      wl_2      wl_3      wl_4      wl_5      wl_6  \\\n0  499191466  0.002749  0.002749  0.002749  0.002749  0.002749  0.002749   \n\n       wl_7      wl_8      wl_9  ...  sigma_274  sigma_275  sigma_276  \\\n0  0.002749  0.002749  0.002749  ...   0.000145   0.000145   0.000145   \n\n   sigma_277  sigma_278  sigma_279  sigma_280  sigma_281  sigma_282  sigma_283  \n0   0.000145   0.000145   0.000145   0.000145   0.000145   0.000145   0.000145  \n\n[1 rows x 567 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>planet_id</th>\n      <th>wl_1</th>\n      <th>wl_2</th>\n      <th>wl_3</th>\n      <th>wl_4</th>\n      <th>wl_5</th>\n      <th>wl_6</th>\n      <th>wl_7</th>\n      <th>wl_8</th>\n      <th>wl_9</th>\n      <th>...</th>\n      <th>sigma_274</th>\n      <th>sigma_275</th>\n      <th>sigma_276</th>\n      <th>sigma_277</th>\n      <th>sigma_278</th>\n      <th>sigma_279</th>\n      <th>sigma_280</th>\n      <th>sigma_281</th>\n      <th>sigma_282</th>\n      <th>sigma_283</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>499191466</td>\n      <td>0.002749</td>\n      <td>0.002749</td>\n      <td>0.002749</td>\n      <td>0.002749</td>\n      <td>0.002749</td>\n      <td>0.002749</td>\n      <td>0.002749</td>\n      <td>0.002749</td>\n      <td>0.002749</td>\n      <td>...</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n      <td>0.000145</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 567 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#                                          arhiv options\n# if LAUNCH_VARIANT == 'option 27':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.0305)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.9695)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n    \n# elif LAUNCH_VARIANT == 'option 28':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.0290)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.9710)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n    \n# elif LAUNCH_VARIANT == 'option 29':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.0302)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.9698)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n\n# elif LAUNCH_VARIANT == 'option 25':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.031)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.969)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n    \n# elif LAUNCH_VARIANT == 'option 26':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.028)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.972)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n\n# if LAUNCH_VARIANT == 'option 24':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.032)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.968)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n    \n# elif LAUNCH_VARIANT == 'option 23':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.026)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.974)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n\n# elif LAUNCH_VARIANT == 'option 22':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.035)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.965)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n    \n# elif LAUNCH_VARIANT == 'option 21':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.03)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.97)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n    \n# if LAUNCH_VARIANT == 'option 20':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.07)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.93)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n    \n# elif LAUNCH_VARIANT == 'option 19':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.05)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.95)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 18':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.020)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.980)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n    \n# elif LAUNCH_VARIANT == 'option 17':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.015)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.985)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 16':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.011)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.989)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 15':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.008)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.992)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 14':\n#     df_solution_x = pd.read_csv('submission_7.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_8 = pd.read_csv('submission_8.csv')\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.005)\n#     df_solution_8 = df_solution_8.map(lambda x:x*0.995)\n#     df_temp = df_solution_7.add(df_solution_8)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 12':\n#     df_solution_x = pd.read_csv('submission_2.csv')\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_2 = df_solution_2.map(lambda x:x*0.05)\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.95)\n#     display(df_solution_2, df_solution_7)\n#     df_temp = df_solution_2.add(df_solution_7)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 11':\n#     df_solution_x = pd.read_csv('submission_2.csv')\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     df_solution_7 = pd.read_csv('submission_7.csv')\n#     df_solution_2 = df_solution_2.map(lambda x:x*0.10)\n#     df_solution_7 = df_solution_7.map(lambda x:x*0.90)\n#     display(df_solution_2, df_solution_7)\n#     df_temp = df_solution_2.add(df_solution_7)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 10':\n#     df_solution_1 = pd.read_csv('submission_1.csv')\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     df_solution_6 = pd.read_csv('submission_6.csv')\n#     display(df_solution_1, df_solution_2, df_solution_6)\n#     df_temp = df_solution_1.add(df_solution_2).add(df_solution_6)\n#     df_submission = df_temp.map(lambda x: x/3)\n#     df_submission['planet_id'] = df_solution_1['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 9':\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     df_solution_6 = pd.read_csv('submission_6.csv')\n#     display(df_solution_2, df_solution_6)\n#     df_temp = df_solution_2.add(df_solution_6)\n#     df_submission = df_temp.map(lambda x: x/2)\n#     df_submission['planet_id'] = df_solution_2['planet_id']\n# \n# elif LAUNCH_VARIANT == 'option 8':\n#     df_solution_x = pd.read_csv('submission_1.csv')\n#     df_solution_1 = pd.read_csv('submission_1.csv')\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     df_solution_1 = df_solution_1.map(lambda x: x*0.07)\n#     df_solution_2 = df_solution_2.map(lambda x: x*0.93)\n#     display(df_solution_1, df_solution_2)\n#     df_temp = df_solution_1.add(df_solution_2)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 7':\n#     df_solution_x = pd.read_csv('submission_1.csv')\n#     df_solution_1 = pd.read_csv('submission_1.csv')\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     df_solution_1 = df_solution_1.map(lambda x: x*0.85)\n#     df_solution_2 = df_solution_2.map(lambda x: x*0.15)\n#     display(df_solution_1, df_solution_2)\n#     df_temp = df_solution_1.add(df_solution_2)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 5':\n#     df_solution_x = pd.read_csv('submission_1.csv')\n#     df_solution_1 = pd.read_csv('submission_1.csv')\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     df_solution_1 = df_solution_1.map(lambda x: x*0.15)\n#     df_solution_2 = df_solution_2.map(lambda x: x*0.85)\n#     display(df_solution_1, df_solution_2)\n#     df_temp = df_solution_1.add(df_solution_2)\n#     df_submission = df_temp.map(lambda x:x)\n#     df_submission['planet_id'] = df_solution_x['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 4':\n#     df_solution_4 = pd.read_csv('submission_4.csv')\n#     df_solution_5 = pd.read_csv('submission_5.csv')\n#     display(df_solution_4, df_solution_5)\n#     df_temp = df_solution_4.add(df_solution_5)\n#     df_submission = df_temp.map(lambda x: x/2)\n#     df_submission['planet_id'] = df_solution_1['planet_id']\n# \n# elif LAUNCH_VARIANT == 'option 3':\n#     df_solution_1 = pd.read_csv('submission_1.csv')\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     df_solution_3 = pd.read_csv('submission_3.csv')\n#     display(df_solution_1, df_solution_2, df_solution_3)\n#     df_temp = df_solution_1.add(df_solution_2).add(df_solution_3)\n#     df_submission = df_temp.map(lambda x: x/3)\n#     df_submission['planet_id'] = df_solution_1['planet_id']\n#\n# elif LAUNCH_VARIANT == 'option 2':\n#     df_solution_3 = pd.read_csv('submission_3.csv')\n#     df_solution_4 = pd.read_csv('submission_4.csv')\n#     df_solution_5 = pd.read_csv('submission_5.csv')\n#     display(df_solution_3, df_solution_4, df_solution_5)\n#     df_temp = df_solution_3.add(df_solution_4).add(df_solution_5)\n#     df_submission = df_temp.map(lambda x: x/3)\n#     df_submission['planet_id'] = df_solution_3['planet_id']\n#      \n# elif LAUNCH_VARIANT == 'option 1':\n#     df_solution_1 = pd.read_csv('submission_1.csv')\n#     df_solution_2 = pd.read_csv('submission_2.csv')\n#     display(df_solution_1, df_solution_2)\n#     df_temp = df_solution_1.add(df_solution_2)\n#     df_submission = df_temp.map(lambda x: x/2)\n#     df_submission['planet_id'] = df_solution_1['planet_id']","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-18T11:40:15.026946Z","iopub.execute_input":"2024-09-18T11:40:15.027448Z","iopub.status.idle":"2024-09-18T11:40:15.046975Z","shell.execute_reply.started":"2024-09-18T11:40:15.027405Z","shell.execute_reply":"2024-09-18T11:40:15.045538Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":90,"outputs":[]}]}